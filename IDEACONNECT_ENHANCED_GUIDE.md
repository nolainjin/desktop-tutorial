# IdeaConnect ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„° ìˆ˜ì§‘ ê°€ì´ë“œ v2.0
## ì–¸ì–´í•™Â·ì¸ì§€ì‹¬ë¦¬í•™Â·AI ê¸°ë°˜ ê³ í•´ìƒë„ ì„¤ê³„

---

## ğŸ¯ í•µì‹¬ ëª©í‘œ ì¬ì •ì˜

### ê¸°ì¡´ ëª©í‘œì˜ ë¬¸ì œì 
- âŒ ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ ì¤‘ì‹¬ â†’ ë§¥ë½ ì†ì‹¤
- âŒ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘ì‹¬ â†’ ê°œë… ê°„ ê´€ê³„ ë¶€ì¬
- âŒ ê²€ìƒ‰ ìµœì í™” ì¤‘ì‹¬ â†’ ë°œê²¬(discovery) ê²½í—˜ ë¶€ì¡±

### ìƒˆë¡œìš´ ëª©í‘œ
**"ì‚¬ê³ ì˜ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ì•„ì´ë””ì–´ ê°„ ìœ ê¸°ì  ì—°ê²°ê³¼ ì°½ë°œì  ë°œê²¬ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤"**

#### ì •ëŸ‰ì  ëª©í‘œ
- **50,000ê°œ ì´ìƒì˜ ë…¸ë“œ(ì•„ì´ë””ì–´)** ìˆ˜ì§‘
- **500,000ê°œ ì´ìƒì˜ ì—£ì§€(ê´€ê³„)** ìƒì„±
- **ë‹¤ì¸µì  ê´€ê³„ë§** êµ¬ì¶• (ì˜ë¯¸ì , ê°ì •ì , ì‹¤ìš©ì , ì—­ì‚¬ì )

#### ì •ì„±ì  ëª©í‘œ
1. **ë§¥ë½ì  ìœ ì‚¬ë„**: í‘œë©´ì  í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì‹¬ì¸µ ì˜ë¯¸ ì—°ê²°
2. **ì°½ë°œì  ë°œê²¬**: ì˜ˆìƒì¹˜ ëª»í•œ ì•„ì´ë””ì–´ ê°„ ì—°ê²° ì§€ì›
3. **ì¸ì§€ ë¶€í•˜ ìµœì í™”**: ì •ë³´ ê³¼ë¶€í•˜ ì—†ì´ í†µì°° ì œê³µ
4. **ê°œì¸í™” ê°€ëŠ¥ì„±**: ì‚¬ìš©ì ì‚¬ê³  íŒ¨í„´ í•™ìŠµ ê¸°ë°˜

---

## ğŸ§  ì¸ì§€ì‹¬ë¦¬í•™ì  ê¸°ë°˜ ì„¤ê³„

### 1. ìŠ¤í‚¤ë§ˆ ì´ë¡  (Schema Theory) ì ìš©

**ì›ë¦¬**: ì¸ê°„ì€ ê°œë…ì„ ë…ë¦½ëœ ì ì´ ì•„ë‹Œ, ì—°ê²°ëœ êµ¬ì¡°(ìŠ¤í‚¤ë§ˆ)ë¡œ ì €ì¥í•œë‹¤.

**êµ¬í˜„ ì „ëµ**:
```json
{
  "id": "node_001",
  "content": "We are what we repeatedly do.",
  "schema_mappings": [
    {
      "schema_type": "ìŠµê´€ í˜•ì„± ìŠ¤í‚¤ë§ˆ",
      "slot": "ê²°ê³¼",
      "related_slots": {
        "ì›ì¸": ["ë°˜ë³µ", "ì‹¤ì²œ"],
        "ë©”ì»¤ë‹ˆì¦˜": ["ì‹ ê²½ê°€ì†Œì„±", "ìë™í™”"],
        "ì‹œê°„ì„±": ["ì¥ê¸°ì ", "ëˆ„ì ì "]
      }
    }
  ]
}
```

**ì¹´í…Œê³ ë¦¬ â†’ ìŠ¤í‚¤ë§ˆ ë³€í™˜**:
| ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ | ìŠ¤í‚¤ë§ˆ | í•˜ìœ„ ìŠ¤í‚¤ë§ˆ |
|-------------|--------|------------|
| ìŠµê´€ | í–‰ë™ ë³€í™” ìŠ¤í‚¤ë§ˆ | ìŠµê´€ í˜•ì„±, ìŠµê´€ ê¹¨ê¸°, ìë™í™” |
| ì„±ì¥ | ë°œë‹¬ ìŠ¤í‚¤ë§ˆ | í•™ìŠµ, ì ì‘, ì§„í™”, ê·¹ë³µ |
| ê´€ê³„ | ì‚¬íšŒì  ì¸ì§€ ìŠ¤í‚¤ë§ˆ | ê³µê°, ì†Œí†µ, ê°ˆë“±, ì‹ ë¢° |

### 2. í™•ì‚° í™œì„±í™” ì´ë¡  (Spreading Activation)

**ì›ë¦¬**: í•˜ë‚˜ì˜ ê°œë…ì´ í™œì„±í™”ë˜ë©´ ê´€ë ¨ëœ ê°œë…ë“¤ì´ ì—°ì‡„ì ìœ¼ë¡œ í™œì„±í™”ëœë‹¤.

**êµ¬í˜„**: ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê´€ê³„ë§
```javascript
{
  "from": "ìŠµê´€",
  "to": "ì •ì²´ì„±",
  "edge_type": "ì¸ê³¼ê´€ê³„",
  "weight": 0.87,  // ê°•í•œ ì—°ê²°
  "activation_decay": 0.15,  // ì „íŒŒ ê°ì‡ ìœ¨
  "bidirectional": true
}
```

**ê´€ê³„ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜**:
- **ì¸ê³¼ê´€ê³„** (A â†’ B): 0.8-0.95 (ê°•í•¨)
- **ìœ ì‚¬ê´€ê³„** (A â‰ˆ B): 0.6-0.8 (ì¤‘ê°„)
- **ëŒ€ì¡°ê´€ê³„** (A â‰  B): 0.5-0.7 (ì•½í•¨, ê·¸ëŸ¬ë‚˜ ì¤‘ìš”)
- **ë§¥ë½ì ** (A contextualâ†’ B): 0.4-0.6 (ì•½í•¨)

### 3. ì •êµí™” ê°€ëŠ¥ì„± ëª¨ë¸ (Elaboration Likelihood Model)

**ì›ë¦¬**: ì •ë³´ ì²˜ë¦¬ ê¹Šì´ì— ë”°ë¼ ì¤‘ì‹¬ ê²½ë¡œ(ê¹Šì€ ì‚¬ê³ )ì™€ ì£¼ë³€ ê²½ë¡œ(íœ´ë¦¬ìŠ¤í‹±) êµ¬ë¶„

**êµ¬í˜„**: ì´ì¤‘ ê²€ìƒ‰ ê²½ë¡œ
```typescript
interface SearchResult {
  // ì¤‘ì‹¬ ê²½ë¡œ: ê¹Šì€ ì˜ë¯¸ ë§¤ì¹­
  deep_matches: {
    content: string;
    semantic_similarity: number;  // 0.8+
    reasoning: string;  // ì™œ ì—°ê²°ë˜ëŠ”ì§€ ì„¤ëª…
  }[];
  
  // ì£¼ë³€ ê²½ë¡œ: ë¹ ë¥¸ ì—°ìƒ
  quick_associations: {
    content: string;
    association_type: 'keyword' | 'emotion' | 'metaphor';
    strength: number;  // 0.5-0.7
  }[];
}
```

---

## ğŸ”¤ ì–¸ì–´í•™ì  ê¸°ë°˜ ì„¤ê³„

### 1. í”„ë ˆì„ ì˜ë¯¸ë¡  (Frame Semantics)

**ì›ë¦¬** (Charles Fillmore): ë‹¨ì–´ëŠ” í”„ë ˆì„(ìƒí™© êµ¬ì¡°) ë‚´ì—ì„œ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤.

**ì˜ˆì‹œ**: "êµ¬ë§¤" í”„ë ˆì„
```yaml
í”„ë ˆì„: ìƒì—…ì _ê±°ë˜
í•µì‹¬_ìš”ì†Œ:
  - êµ¬ë§¤ì (Buyer)
  - íŒë§¤ì (Seller)
  - ìƒí’ˆ (Goods)
  - ëŒ€ê°€ (Money)
  - ì‹œì  (Time)

ì—°ê²°_í”„ë ˆì„:
  - ì†Œìœ _ë³€ê²½
  - ê²½ì œ_êµí™˜
  - ì„ íƒ_í–‰ìœ„
```

**ë°ì´í„° êµ¬ì¡° ì ìš©**:
```json
{
  "id": "quote_315",
  "content": "The best time to plant a tree was 20 years ago. The second best time is now.",
  "primary_frame": "ì‹œê°„ê³¼_í–‰ë™",
  "frame_elements": {
    "action": "ì‹¬ê¸° (ì‹ìˆ˜)",
    "optimal_time": "ê³¼ê±° (20ë…„ ì „)",
    "alternative_time": "í˜„ì¬",
    "implicit_message": "ì§€ê¸ˆ_ì‹œì‘í•˜ê¸°"
  },
  "frame_relations": [
    {
      "related_frame": "í›„íšŒì™€_íšŒë³µ",
      "relation": "inheritance"  // ìƒì† ê´€ê³„
    },
    {
      "related_frame": "ê¸°íšŒ_í¬ì°©",
      "relation": "subframe"
    }
  ]
}
```

### 2. ê°œë…ì  ì€ìœ  ì´ë¡  (Conceptual Metaphor Theory)

**ì›ë¦¬** (Lakoff & Johnson): ì¶”ìƒì  ê°œë…ì€ êµ¬ì²´ì  ì€ìœ ë¡œ ì´í•´ëœë‹¤.

**í•µì‹¬ ì€ìœ  ì²´ê³„ ì‹ë³„**:
```javascript
const CONCEPTUAL_METAPHORS = {
  "ì‹œê°„ì€_ìì›ì´ë‹¤": {
    "source_domain": "ë¬¼ì§ˆì _ìì›",
    "target_domain": "ì‹œê°„",
    "mappings": {
      "spending": "ë³´ë‚´ë‹¤",
      "saving": "ì•„ë¼ë‹¤",
      "wasting": "ë‚­ë¹„í•˜ë‹¤",
      "investing": "íˆ¬ìí•˜ë‹¤"
    },
    "example_quotes": [
      "Time is money",
      "Don't waste your time"
    ]
  },
  
  "ì¸ìƒì€_ì—¬ì •ì´ë‹¤": {
    "source_domain": "ë¬¼ë¦¬ì _ì—¬í–‰",
    "target_domain": "ì¸ìƒ",
    "mappings": {
      "path": "ê¸¸/ê²½ë¡œ",
      "obstacles": "ì¥ì• ë¬¼",
      "destination": "ëª©í‘œ",
      "companions": "ë™ë°˜ì"
    }
  },
  
  "ì•„ì´ë””ì–´ëŠ”_ê±´ë¬¼ì´ë‹¤": {
    "source_domain": "ê±´ì¶•",
    "target_domain": "ì¶”ë¡ ",
    "mappings": {
      "foundation": "ê¸°ì´ˆ/ì „ì œ",
      "structure": "ë…¼ë¦¬_êµ¬ì¡°",
      "collapse": "ë…¼ë¦¬_ë¶•ê´´"
    }
  }
}
```

**ë°ì´í„° ìˆ˜ì§‘ ì‹œ ì€ìœ  íƒœê¹…**:
```json
{
  "content": "Build your argument on solid foundations",
  "metaphor": {
    "system": "ì•„ì´ë””ì–´ëŠ”_ê±´ë¬¼ì´ë‹¤",
    "elements": ["build", "foundations"],
    "related_metaphors": ["ì•„ì´ë””ì–´ëŠ”_ì‹ë¬¼ì´ë‹¤"]  // êµì°¨ ì€ìœ 
  }
}
```

### 3. ì˜ë¯¸ ì—­í•  ì´ë¡  (Semantic Role Labeling)

**ì›ë¦¬**: ë¬¸ì¥ì˜ ì‹¬ì¸µ êµ¬ì¡°ë¥¼ í–‰ìœ„ì-í–‰ìœ„-ëŒ€ìƒìœ¼ë¡œ ë¶„í•´

**ì ìš©**:
```python
# ì˜ë¯¸ ì—­í•  ìë™ íƒœê¹…
{
  "content": "Courage is not the absence of fear, but the triumph over it.",
  "semantic_roles": {
    "theme": "ìš©ê¸°",  # ì£¼ì œ
    "attribute": "ë‘ë ¤ì›€ì˜_ë¶€ì¬ê°€_ì•„ë‹˜",  # ì†ì„± (ë¶€ì •)
    "attribute_corrected": "ë‘ë ¤ì›€ì—_ëŒ€í•œ_ìŠ¹ë¦¬",  # ì‹¤ì œ ì†ì„±
    "implicit_agent": "ìš©ê¸°ìˆëŠ”_ì‚¬ëŒ"  # ì•”ë¬µì  í–‰ìœ„ì
  },
  "deep_structure": {
    "proposition": "ìš©ê¸° = ê·¹ë³µ(í–‰ìœ„ì, ë‘ë ¤ì›€)",
    "negation": "ìš©ê¸° â‰  ë¶€ì¬(ë‘ë ¤ì›€)"
  }
}
```

---

## ğŸ¤– AI/NLP ê¸°ìˆ  ê¸°ë°˜ ì„¤ê³„

### 1. ì„ë² ë”© ë²¡í„° ê³µê°„ (Embedding Space)

**ê¸°ìˆ **: Sentence Transformers / OpenAI Embeddings

**êµ¬í˜„**:
```python
from sentence_transformers import SentenceTransformer
import numpy as np

# ë‹¤ì¤‘ ì„ë² ë”© ì „ëµ
class MultiEmbedding:
    def __init__(self):
        # ì˜ë¯¸ì  ì„ë² ë”© (semantic)
        self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # ê°ì •ì  ì„ë² ë”© (emotional)
        self.emotion_model = SentenceTransformer('emotion-english-distilroberta-base')
        
        # ì˜ë„ ì„ë² ë”© (pragmatic)
        self.intent_model = SentenceTransformer('intent-classification')
    
    def encode(self, text):
        return {
            'semantic': self.semantic_model.encode(text),
            'emotional': self.emotion_model.encode(text),
            'pragmatic': self.intent_model.encode(text)
        }

# ë‹¤ì°¨ì› ìœ ì‚¬ë„ ê³„ì‚°
def multi_dimensional_similarity(vec1, vec2, weights):
    """
    weights: {
        'semantic': 0.5,
        'emotional': 0.3,
        'pragmatic': 0.2
    }
    """
    similarities = {}
    for dimension in ['semantic', 'emotional', 'pragmatic']:
        cos_sim = cosine_similarity(
            vec1[dimension], 
            vec2[dimension]
        )
        similarities[dimension] = cos_sim
    
    weighted_sim = sum(
        similarities[dim] * weights[dim] 
        for dim in weights
    )
    
    return weighted_sim, similarities
```

**ë°ì´í„° ì €ì¥**:
```json
{
  "id": "node_001",
  "content": "...",
  "embeddings": {
    "semantic_v": [0.123, -0.456, ...],  // 768 dim
    "emotional_v": [0.789, 0.234, ...],  // 768 dim
    "pragmatic_v": [-0.345, 0.678, ...]  // 768 dim
  },
  "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
  "version": "2.0"
}
```

### 2. ì§€ì‹ ê·¸ë˜í”„ ì„ë² ë”© (Knowledge Graph Embedding)

**ê¸°ìˆ **: TransE, ComplEx, RotatE

**ëª©ì **: (entity, relation, entity) ì‚¼ì¤‘í•­ì„ ë²¡í„° ê³µê°„ì— ë°°ì¹˜

**êµ¬í˜„**:
```python
# TransE ëª¨ë¸ (ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì )
class TransE:
    """
    h + r â‰ˆ t
    head entity + relation â‰ˆ tail entity
    """
    
    def train(self, triples):
        # triples: [("ìŠµê´€", "leads_to", "ì •ì²´ì„±"), ...]
        
        for (h, r, t) in triples:
            h_vec = self.entity_embeddings[h]
            r_vec = self.relation_embeddings[r]
            t_vec = self.entity_embeddings[t]
            
            # ì†ì‹¤: ||h + r - t||
            loss = np.linalg.norm(h_vec + r_vec - t_vec)
            self.optimize(loss)
    
    def predict_tail(self, head, relation):
        """ì£¼ì–´ì§„ (head, relation)ìœ¼ë¡œ tail ì˜ˆì¸¡"""
        h_vec = self.entity_embeddings[head]
        r_vec = self.relation_embeddings[relation]
        
        predicted_t = h_vec + r_vec
        
        # ê°€ì¥ ê°€ê¹Œìš´ entity ì°¾ê¸°
        return self.find_nearest_entity(predicted_t)

# ì‚¬ìš© ì˜ˆì‹œ
model = TransE()
model.train(knowledge_triples)

# "ìŠµê´€" + "ê²°ê³¼ëŠ”" â†’ ?
result = model.predict_tail("ìŠµê´€", "ê²°ê³¼ëŠ”")
# â†’ "ì •ì²´ì„±" (ë†’ì€ í™•ë¥ )
```

### 3. ê´€ê³„ ì¶”ì¶œ (Relation Extraction)

**ë°©ë²•**: ì‚¬ì „ ì •ì˜ + ê¸°ê³„í•™ìŠµ

**ê´€ê³„ ì˜¨í†¨ë¡œì§€**:
```yaml
ê´€ê³„_ì²´ê³„:
  ì¸ê³¼_ê´€ê³„:
    - causes: Aê°€ Bë¥¼ ì•¼ê¸°í•¨
    - enables: Aê°€ Bë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨
    - prevents: Aê°€ Bë¥¼ ë§‰ìŒ
    - requires: Aê°€ Bë¥¼ í•„ìš”ë¡œ í•¨
  
  êµ¬ì¡°_ê´€ê³„:
    - part_of: AëŠ” Bì˜ ë¶€ë¶„
    - instance_of: AëŠ” Bì˜ ì‚¬ë¡€
    - contrasts_with: AëŠ” Bì™€ ëŒ€ì¡°ë¨
  
  ì‹œê°„_ê´€ê³„:
    - precedes: Aê°€ Bë³´ë‹¤ ë¨¼ì €
    - follows: Aê°€ Bë¥¼ ë”°ë¦„
    - during: AëŠ” B ë™ì•ˆ
  
  ì˜ë¯¸_ê´€ê³„:
    - similar_to: ìœ ì‚¬í•¨
    - analogous_to: ìœ ì¶” ê°€ëŠ¥
    - metaphor_of: ì€ìœ  ê´€ê³„
    
  ê°ì •_ê´€ê³„:
    - evokes: Aê°€ B ê°ì •ì„ ìœ ë°œ
    - expressed_by: AëŠ” Bë¡œ í‘œí˜„ë¨
```

**ìë™ ê´€ê³„ ì¶”ì¶œ**:
```python
import spacy
from transformers import pipeline

nlp = spacy.load("en_core_web_trf")
relation_extractor = pipeline(
    "text-classification",
    model="relation-extraction-model"
)

def extract_relations(quote1, quote2):
    """ë‘ ëª…ì–¸ ê°„ ê´€ê³„ ìë™ ì¶”ì¶œ"""
    
    # 1. ê³µí†µ ê°œë… ì¶”ì¶œ
    doc1 = nlp(quote1)
    doc2 = nlp(quote2)
    
    concepts1 = [ent.text for ent in doc1.ents]
    concepts2 = [ent.text for ent in doc2.ents]
    
    shared = set(concepts1) & set(concepts2)
    
    # 2. ì˜ë¯¸ì  ìœ ì‚¬ë„
    similarity = doc1.similarity(doc2)
    
    # 3. ë…¼ë¦¬ì  ê´€ê³„ ì¶”ë¡ 
    relations = []
    
    if similarity > 0.8:
        relations.append(("similar_to", similarity))
    
    if has_causal_markers(quote1, quote2):
        relations.append(("causes", 0.7))
    
    if has_contrast_markers(quote1, quote2):
        relations.append(("contrasts_with", 0.6))
    
    return relations
```

---

## ğŸ“Š í–¥ìƒëœ ë°ì´í„° ìŠ¤í‚¤ë§ˆ

### ë…¸ë“œ(Node) êµ¬ì¡° - ë‹¤ì¸µì  í‘œí˜„

```typescript
interface IdeaNode {
  // === ê¸°ë³¸ ì‹ë³„ ===
  id: string;
  content: string;
  content_ko?: string;
  
  // === ì¶œì²˜ ë©”íƒ€ë°ì´í„° ===
  source: {
    author: string;
    work: string;
    year: number;
    url?: string;
    isbn?: string;
    doi?: string;
  };
  
  // === ì–¸ì–´í•™ì  ë¶„ì„ ===
  linguistic: {
    // í”„ë ˆì„ ì˜ë¯¸ë¡ 
    primary_frame: string;
    frame_elements: Record<string, string>;
    related_frames: string[];
    
    // ì€ìœ  ë¶„ì„
    metaphors: {
      system: string;  // "ì‹œê°„ì€_ìì›ì´ë‹¤"
      elements: string[];
      source_domain: string;
      target_domain: string;
    }[];
    
    // ì˜ë¯¸ ì—­í• 
    semantic_roles: {
      theme: string;
      agent?: string;
      patient?: string;
      instrument?: string;
    };
    
    // í™”í–‰ ì´ë¡  (Speech Act)
    speech_act: 'assertive' | 'directive' | 'commissive' | 'expressive';
  };
  
  // === ì¸ì§€ì‹¬ë¦¬í•™ì  ë¶„ì„ ===
  cognitive: {
    // ìŠ¤í‚¤ë§ˆ ë§¤í•‘
    schemas: {
      type: string;
      slot: string;
      related_slots: Record<string, string[]>;
    }[];
    
    // ì •ë³´ ì²˜ë¦¬ ìˆ˜ì¤€
    processing_level: 'surface' | 'semantic' | 'pragmatic';
    
    // ì¸ì§€ ë¶€í•˜
    cognitive_load: 'low' | 'medium' | 'high';
    
    // ê¸°ì–µ ì¸ì¶œ ë‹¨ì„œ
    retrieval_cues: string[];
  };
  
  // === ê°ì •/íƒœë„ ë¶„ì„ ===
  affective: {
    // ê°ì • ë²¡í„° (Plutchikì˜ 8ê°€ì§€ ê¸°ë³¸ ê°ì •)
    emotions: {
      joy: number;
      trust: number;
      fear: number;
      surprise: number;
      sadness: number;
      disgust: number;
      anger: number;
      anticipation: number;
    };
    
    // ê°ì •ê°€ (Valence)
    valence: number;  // -1 (negative) ~ +1 (positive)
    
    // ê°ì„±ë„ (Arousal)
    arousal: number;  // 0 (calm) ~ 1 (excited)
    
    // ì§€ë°°ì„± (Dominance)
    dominance: number;  // 0 (submissive) ~ 1 (dominant)
  };
  
  // === ì‹¤ìš©ì  ì°¨ì› ===
  pragmatic: {
    // ì ìš© ê°€ëŠ¥í•œ ìƒí™©
    applicable_contexts: string[];
    
    // í–‰ë™ ìœ ë„ì„± (Affordance)
    action_tendencies: string[];
    
    // ì‹¤ì²œ ë‚œì´ë„
    implementation_difficulty: 'easy' | 'medium' | 'hard';
    
    // ì‹œê°„ ì§€í‰
    time_horizon: 'immediate' | 'short-term' | 'long-term';
  };
  
  // === ë²¡í„° ì„ë² ë”© ===
  embeddings: {
    semantic: number[];     // 768-dim
    emotional: number[];    // 768-dim
    pragmatic: number[];    // 768-dim
    kg_embedding: number[]; // 128-dim (ì§€ì‹ ê·¸ë˜í”„)
  };
  
  // === í†µê³„ ì •ë³´ ===
  stats: {
    view_count: number;
    connection_count: number;
    user_saved_count: number;
    avg_rating: number;
  };
}
```

### ì—£ì§€(Edge) êµ¬ì¡° - ë‹¤ì¤‘ ê´€ê³„

```typescript
interface IdeaEdge {
  id: string;
  from: string;  // node id
  to: string;    // node id
  
  // === ê´€ê³„ ìœ í˜• ===
  relation_type: RelationType;
  
  // === ê´€ê³„ ê°•ë„ ===
  strength: number;  // 0.0 ~ 1.0
  
  // === ê´€ê³„ ì°¨ì›ë³„ ì ìˆ˜ ===
  dimensions: {
    semantic_similarity: number;     // ì˜ë¯¸ì  ìœ ì‚¬ì„±
    emotional_resonance: number;     // ê°ì •ì  ê³µëª…
    pragmatic_alignment: number;     // ì‹¤ìš©ì  ì •ë ¬
    metaphorical_connection: number; // ì€ìœ ì  ì—°ê²°
    causal_strength: number;         // ì¸ê³¼ ê´€ê³„ ê°•ë„
  };
  
  // === ê´€ê³„ ì„¤ëª… ===
  reasoning: {
    automatic: string;  // AI ìë™ ìƒì„±
    curated?: string;   // íë ˆì´í„° ìˆ˜ë™ ì‘ì„±
  };
  
  // === ì–‘ë°©í–¥ì„± ===
  bidirectional: boolean;
  reverse_relation?: RelationType;
  
  // === ì»¨í…ìŠ¤íŠ¸ ===
  context_dependent: boolean;
  contexts?: string[];  // ì–´ë–¤ ë§¥ë½ì—ì„œ ì´ ê´€ê³„ê°€ ìœ íš¨í•œê°€
  
  // === ì‹ ë¢°ë„ ===
  confidence: number;  // 0.0 ~ 1.0
  source: 'algorithm' | 'expert' | 'community';
  
  // === ì‹œê°„ ì •ë³´ ===
  created_at: Date;
  last_activated: Date;
  activation_count: number;
}

type RelationType = 
  // ì˜ë¯¸ì 
  | 'similar_to'
  | 'opposite_to'
  | 'part_of'
  | 'example_of'
  | 'generalizes_to'
  
  // ì¸ê³¼ì 
  | 'causes'
  | 'enables'
  | 'prevents'
  | 'requires'
  
  // ì‹œê°„ì 
  | 'precedes'
  | 'follows'
  | 'concurrent_with'
  
  // ë…¼ë¦¬ì 
  | 'supports'
  | 'contradicts'
  | 'refines'
  | 'extends'
  
  // ì€ìœ ì 
  | 'metaphor_of'
  | 'analogy_to'
  
  // ê°ì •ì 
  | 'evokes_same_emotion'
  | 'contrasting_emotion'
  
  // ì‹¤ìš©ì 
  | 'implements_same_principle'
  | 'alternative_approach';
```

---

## ğŸ”¬ ìˆ˜ì§‘ ë°©ë²•ë¡  - 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸

### Phase 1: Raw Collection (ì›ì‹œ ìˆ˜ì§‘)
**ëª©í‘œ**: 50,000ê°œ ì›ì‹œ ë°ì´í„°

```python
# 1. API ê¸°ë°˜ ëŒ€ëŸ‰ ìˆ˜ì§‘
quotable_quotes = fetch_from_quotable_api(10000)
goodreads_quotes = fetch_from_goodreads(8000)
wikiquote = scrape_wikiquote(7000)

# 2. ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
for quote in raw_quotes:
    quote['id'] = generate_id()
    quote['source'] = extract_source(quote)
    quote['basic_keywords'] = extract_keywords_tfidf(quote.content)
```

### Phase 2: Enrichment (ê°•í™”)
**ëª©í‘œ**: ì–¸ì–´í•™Â·ì‹¬ë¦¬í•™ì  ì£¼ì„ ì¶”ê°€

```python
from transformers import pipeline
import spacy

# ì–¸ì–´í•™ì  ë¶„ì„ê¸°
nlp = spacy.load("en_core_web_trf")
metaphor_detector = pipeline("text-classification", model="metaphor-detection")
emotion_analyzer = pipeline("text-classification", model="emotion")

def enrich_quote(quote):
    doc = nlp(quote.content)
    
    # 1. í”„ë ˆì„ ì˜ë¯¸ë¡  ë¶„ì„
    quote.linguistic.primary_frame = detect_frame(doc)
    quote.linguistic.frame_elements = extract_frame_elements(doc)
    
    # 2. ì€ìœ  ë¶„ì„
    metaphors = metaphor_detector(quote.content)
    quote.linguistic.metaphors = classify_metaphors(metaphors)
    
    # 3. ê°ì • ë¶„ì„
    emotions = emotion_analyzer(quote.content)
    quote.affective.emotions = parse_emotions(emotions)
    
    # 4. ì„ë² ë”© ìƒì„±
    quote.embeddings.semantic = semantic_model.encode(quote.content)
    quote.embeddings.emotional = emotion_model.encode(quote.content)
    quote.embeddings.pragmatic = intent_model.encode(quote.content)
    
    return quote
```

### Phase 3: Graph Construction (ê·¸ë˜í”„ êµ¬ì¶•)
**ëª©í‘œ**: 500,000+ ê´€ê³„ ìƒì„±

```python
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity

def construct_knowledge_graph(enriched_quotes):
    G = nx.DiGraph()
    
    # 1. ë…¸ë“œ ì¶”ê°€
    for quote in enriched_quotes:
        G.add_node(quote.id, data=quote)
    
    # 2. ì—£ì§€ ìë™ ìƒì„±
    for i, q1 in enumerate(enriched_quotes):
        for q2 in enriched_quotes[i+1:]:
            # ë‹¤ì°¨ì› ìœ ì‚¬ë„ ê³„ì‚°
            similarities = calculate_multi_dim_similarity(q1, q2)
            
            # ì„ê³„ê°’ ì´ìƒì´ë©´ ì—£ì§€ ìƒì„±
            if similarities['weighted'] > 0.65:
                edge = create_edge(q1, q2, similarities)
                G.add_edge(q1.id, q2.id, data=edge)
    
    # 3. ì¶”ê°€ ê´€ê³„ ì¶”ë¡ 
    infer_causal_relations(G)
    infer_metaphorical_relations(G)
    detect_communities(G)
    
    # 4. ê·¸ë˜í”„ ìµœì í™”
    prune_weak_edges(G, threshold=0.5)
    add_shortcuts(G)  # ìì£¼ í•¨ê»˜ ì ‘ê·¼ë˜ëŠ” ë…¸ë“œ ê°„ ì§ì ‘ ì—°ê²°
    
    return G

def calculate_multi_dim_similarity(q1, q2):
    """ë‹¤ì°¨ì› ìœ ì‚¬ë„ ê³„ì‚°"""
    
    # ì˜ë¯¸ì  ìœ ì‚¬ë„ (semantic)
    sem_sim = cosine_similarity(
        q1.embeddings.semantic,
        q2.embeddings.semantic
    )[0][0]
    
    # ê°ì •ì  ìœ ì‚¬ë„ (emotional)
    emo_sim = calculate_emotion_similarity(
        q1.affective.emotions,
        q2.affective.emotions
    )
    
    # ì‹¤ìš©ì  ìœ ì‚¬ë„ (pragmatic)
    prag_sim = jaccard_similarity(
        q1.pragmatic.applicable_contexts,
        q2.pragmatic.applicable_contexts
    )
    
    # ì€ìœ ì  ì—°ê²° (metaphorical)
    meta_sim = check_shared_metaphors(
        q1.linguistic.metaphors,
        q2.linguistic.metaphors
    )
    
    # ê°€ì¤‘ í‰ê·  (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë™ì  ì¡°ì • ê°€ëŠ¥)
    weighted = (
        sem_sim * 0.4 +
        emo_sim * 0.25 +
        prag_sim * 0.2 +
        meta_sim * 0.15
    )
    
    return {
        'semantic': sem_sim,
        'emotional': emo_sim,
        'pragmatic': prag_sim,
        'metaphorical': meta_sim,
        'weighted': weighted
    }
```

---

## ğŸ¨ ê·¸ë˜í”„ ì‹œê°í™” - ì˜µì‹œë””ì–¸ ìŠ¤íƒ€ì¼

### ì‹œê°í™” ê³„ì¸µ

```typescript
interface GraphVisualization {
  // Layer 1: ê¸€ë¡œë²Œ ë·° (ì „ì²´ ì§€ì‹ ê³µê°„)
  global: {
    layout: 'force-directed' | '3d-sphere';
    node_size: 'by_connections' | 'by_importance';
    color_scheme: 'by_category' | 'by_emotion' | 'by_time';
    clusters: Community[];
  };
  
  // Layer 2: ë¡œì»¬ ë·° (í˜„ì¬ ë…¸ë“œ ì¤‘ì‹¬)
  local: {
    focus_node: string;
    depth: 1 | 2 | 3;  // ì—°ê²° ê¹Šì´
    highlighted_relations: RelationType[];
    filter: {
      min_strength: number;
      relation_types: RelationType[];
    };
  };
  
  // Layer 3: íŒ¨ìŠ¤ ë·° (ì•„ì´ë””ì–´ ì—¬ì •)
  path: {
    start_node: string;
    end_node: string;
    paths: Path[];  // ì—¬ëŸ¬ ê²½ë¡œ í‘œì‹œ
    path_score: number;  // ê²½ë¡œ ê°•ë„
  };
}

// ì»¤ë®¤ë‹ˆí‹° ê°ì§€ (Louvain Algorithm)
interface Community {
  id: string;
  name: string;  // "ìŠµê´€ê³¼ ì •ì²´ì„± í´ëŸ¬ìŠ¤í„°"
  nodes: string[];
  cohesion: number;  // ì‘ì§‘ë„
  central_node: string;  // ì¤‘ì‹¬ ë…¸ë“œ
  description: string;
}
```

### ì¸í„°ë™ì…˜ ë””ìì¸

```typescript
// ë…¸ë“œ í˜¸ë²„ ì‹œ
onNodeHover(node: IdeaNode) {
  // 1ì°¨ ì—°ê²° í•˜ì´ë¼ì´íŠ¸
  highlightConnections(node, depth: 1);
  
  // ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
  showPreview({
    content: node.content,
    author: node.source.author,
    key_connections: getTopConnections(node, 5),
    emotional_tone: visualizeEmotions(node.affective),
  });
}

// ë…¸ë“œ í´ë¦­ ì‹œ
onNodeClick(node: IdeaNode) {
  // ë¡œì»¬ ê·¸ë˜í”„ë¡œ ì „í™˜
  transitionToLocalView(node);
  
  // ê´€ë ¨ ì•„ì´ë””ì–´ íŒ¨ë„ í‘œì‹œ
  showRelatedIdeas({
    similar: findSimilarNodes(node, threshold: 0.8),
    contrasting: findContrastingNodes(node),
    causal_next: findCausallyRelatedNodes(node, direction: 'forward'),
    metaphorical: findMetaphoricallyRelatedNodes(node),
  });
  
  // ì‚¬ìš©ì ë©”ëª¨ì™€ ì—°ê²°
  connectToUserNotes(node);
}

// ì—£ì§€ í´ë¦­ ì‹œ
onEdgeClick(edge: IdeaEdge) {
  // ê´€ê³„ ì„¤ëª… í‘œì‹œ
  showRelationshipExplanation({
    type: edge.relation_type,
    strength: edge.strength,
    reasoning: edge.reasoning,
    dimensions: visualizeDimensions(edge.dimensions),
  });
  
  // ìœ ì‚¬í•œ ê´€ê³„ ì°¾ê¸°
  findSimilarRelationships(edge);
}

// ê²€ìƒ‰ ì‹œ
onSearch(query: string, userContext: UserContext) {
  // ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜
  const weights = adaptWeights(userContext);
  
  // ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
  const results = {
    semantic: searchSemantic(query, weights.semantic),
    emotional: searchByEmotion(query, weights.emotional),
    pragmatic: searchByContext(userContext.current_goals, weights.pragmatic),
    serendipitous: findUnexpectedConnections(query, 0.3),  // 30% ìš°ì—°í•œ ë°œê²¬
  };
  
  // í†µí•© ë° ìˆœìœ„í™”
  return mergeAndRank(results, weights);
}
```

---

## ğŸ§ª í’ˆì§ˆ ê´€ë¦¬ - 3-Tier ê²€ì¦

### Tier 1: ìë™ ê²€ì¦ (100%)

```python
class AutomaticValidator:
    def validate_node(self, node: IdeaNode) -> ValidationReport:
        errors = []
        warnings = []
        
        # 1. í•„ìˆ˜ í•„ë“œ ì¡´ì¬
        if not node.id or not node.content:
            errors.append("í•„ìˆ˜ í•„ë“œ ëˆ„ë½")
        
        # 2. ê¸¸ì´ ê²€ì¦
        if len(node.content) < 10:
            errors.append("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ")
        if len(node.content) > 500:
            warnings.append("ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¸ì§€ ë¶€í•˜ ìš°ë ¤")
        
        # 3. ì„ë² ë”© í’ˆì§ˆ
        if np.isnan(node.embeddings.semantic).any():
            errors.append("ì„ë² ë”© ë²¡í„° ì˜¤ë¥˜")
        
        # 4. ë©”íƒ€ë°ì´í„° ì™„ì„±ë„
        completeness = self.check_completeness(node)
        if completeness < 0.7:
            warnings.append(f"ë©”íƒ€ë°ì´í„° ì™„ì„±ë„ ë‚®ìŒ: {completeness}")
        
        # 5. ì¤‘ë³µ ì²´í¬
        if self.is_duplicate(node):
            errors.append("ì¤‘ë³µëœ ì½˜í…ì¸ ")
        
        return ValidationReport(errors, warnings)
    
    def validate_edge(self, edge: IdeaEdge) -> ValidationReport:
        errors = []
        warnings = []
        
        # 1. ë…¸ë“œ ì¡´ì¬ í™•ì¸
        if not self.node_exists(edge.from) or not self.node_exists(edge.to):
            errors.append("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì°¸ì¡°")
        
        # 2. ê´€ê³„ ê°•ë„ ê²€ì¦
        if edge.strength < 0.5:
            warnings.append("ì•½í•œ ê´€ê³„ (ì œê±° ê³ ë ¤)")
        
        # 3. ìˆœí™˜ ê´€ê³„ ì²´í¬
        if self.creates_cycle(edge) and not edge.bidirectional:
            warnings.append("ìˆœí™˜ ê´€ê³„ ìƒì„±")
        
        # 4. ì°¨ì›ë³„ ì¼ê´€ì„±
        if self.dimension_inconsistency(edge):
            warnings.append("ì°¨ì› ê°„ ë¶ˆì¼ì¹˜")
        
        return ValidationReport(errors, warnings)
```

### Tier 2: ì „ë¬¸ê°€ íë ˆì´ì…˜ (10%)

```python
class ExpertCuration:
    """
    ëª©í‘œ: ìƒìœ„ 10% ë…¸ë“œ/ì—£ì§€ë¥¼ ì „ë¬¸ê°€ê°€ ìˆ˜ë™ ê²€í† 
    """
    
    def select_for_curation(self, nodes: List[IdeaNode]) -> List[IdeaNode]:
        # 1. ë†’ì€ ì—°ê²°ì„± (í—ˆë¸Œ ë…¸ë“œ)
        high_degree = [n for n in nodes if n.stats.connection_count > 50]
        
        # 2. ë‚®ì€ ì‹ ë¢°ë„
        low_confidence = [n for n in nodes if self.get_avg_edge_confidence(n) < 0.7]
        
        # 3. ê°ì •ì  ë³µì¡ì„±
        complex_emotions = [n for n in nodes if self.emotion_entropy(n) > 2.0]
        
        # 4. ì€ìœ ì  ì¤‘ìš”ì„±
        metaphorical_key = [n for n in nodes if len(n.linguistic.metaphors) > 2]
        
        return list(set(high_degree + low_confidence + complex_emotions + metaphorical_key))
    
    def expert_review_interface(self, node: IdeaNode):
        """ì „ë¬¸ê°€ ë¦¬ë·° UI"""
        return {
            "content": node.content,
            "current_analysis": {
                "frames": node.linguistic.primary_frame,
                "metaphors": node.linguistic.metaphors,
                "emotions": node.affective.emotions,
            },
            "questions": [
                "í”„ë ˆì„ ë¶„ë¥˜ê°€ ì •í™•í•œê°€?",
                "ì€ìœ  ê°ì§€ê°€ ì ì ˆí•œê°€?",
                "ê°ì • ë¶„ì„ì´ íƒ€ë‹¹í•œê°€?",
                "ë†“ì¹œ ê´€ê³„ê°€ ìˆëŠ”ê°€?",
            ],
            "suggested_connections": self.find_potential_connections(node),
            "revision_history": node.revisions,
        }
```

### Tier 3: ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°± (ë™ì )

```python
class CommunityFeedback:
    def collect_implicit_feedback(self, user_id: str, session: Session):
        """ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜ ì•”ë¬µì  í”¼ë“œë°±"""
        
        feedback = []
        
        # 1. ë…¸ë“œ ì²´ë¥˜ ì‹œê°„
        for node_id, duration in session.node_dwell_times.items():
            if duration > 10:  # 10ì´ˆ ì´ìƒ
                feedback.append({
                    "type": "positive_engagement",
                    "node": node_id,
                    "strength": min(duration / 60, 1.0),
                })
        
        # 2. ì—°ê²° íƒìƒ‰ íŒ¨í„´
        for path in session.exploration_paths:
            if len(path) > 3:  # ê¹Šì€ íƒìƒ‰
                feedback.append({
                    "type": "valuable_path",
                    "path": path,
                    "strength": 0.7,
                })
        
        # 3. ì €ì¥/ë¶ë§ˆí¬
        for saved_node in session.saved_nodes:
            feedback.append({
                "type": "explicit_save",
                "node": saved_node,
                "strength": 1.0,
            })
        
        # 4. ì‚¬ìš©ì ë©”ëª¨ì™€ ì—°ê²°
        for note_link in session.user_note_links:
            feedback.append({
                "type": "user_integration",
                "node": note_link.idea_node,
                "user_note": note_link.user_note,
                "strength": 0.9,
            })
        
        return feedback
    
    def aggregate_feedback(self, node: IdeaNode) -> NodeQualityScore:
        """ëª¨ë“  ì‚¬ìš©ì í”¼ë“œë°± ì§‘ê³„"""
        
        all_feedback = self.get_feedback_for_node(node.id)
        
        quality_score = {
            "engagement": np.mean([f.strength for f in all_feedback if f.type == "positive_engagement"]),
            "utility": len([f for f in all_feedback if f.type == "explicit_save"]) / max(node.stats.view_count, 1),
            "integration": len([f for f in all_feedback if f.type == "user_integration"]) / max(node.stats.view_count, 1),
        }
        
        # ê°€ì¤‘ í‰ê· 
        overall = (
            quality_score["engagement"] * 0.3 +
            quality_score["utility"] * 0.4 +
            quality_score["integration"] * 0.3
        )
        
        return NodeQualityScore(overall, quality_score)
```

---

## ğŸš€ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: Foundation (Week 1-4)
**ëª©í‘œ**: ê¸°ë³¸ ì¸í”„ë¼ + 10,000ê°œ ë…¸ë“œ

```bash
# ì‘ì—… í•­ëª©
â–¡ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìµœì¢… í™•ì •
â–¡ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
  - API í†µí•© (Quotable, Wikiquote, Google Books)
  - í¬ë¡¤ëŸ¬ êµ¬í˜„ (Medium, ë¸ŒëŸ°ì¹˜)
â–¡ NLP ëª¨ë¸ ì…‹ì—…
  - spaCy íŒŒì´í”„ë¼ì¸
  - Sentence Transformers
  - ê°ì • ë¶„ì„ ëª¨ë¸
â–¡ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„
  - ë…¸ë“œ í…Œì´ë¸”
  - ì—£ì§€ í…Œì´ë¸”
  - ì„ë² ë”© ì¸ë±ìŠ¤ (FAISS/Annoy)
â–¡ 10,000ê°œ ë…¸ë“œ ìˆ˜ì§‘ ë° ê°•í™”
```

### Phase 2: Enrichment (Week 5-8)
**ëª©í‘œ**: ì–¸ì–´í•™Â·ì‹¬ë¦¬í•™ì  ì£¼ì„ + 30,000ê°œ ë…¸ë“œ

```bash
# ì‘ì—… í•­ëª©
â–¡ ìë™ ì£¼ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
  - í”„ë ˆì„ ì˜ë¯¸ë¡  ë¶„ì„ê¸°
  - ì€ìœ  ê°ì§€ê¸°
  - ì˜ë¯¸ ì—­í•  ë ˆì´ë¸”ëŸ¬
â–¡ ê°ì • ë¶„ì„ ê³ ë„í™”
  - Plutchik 8ê°ì • ëª¨ë¸
  - VAD (Valence-Arousal-Dominance)
â–¡ 30,000ê°œ ì¶”ê°€ ë…¸ë“œ ìˆ˜ì§‘ ë° ê°•í™”
â–¡ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•
```

### Phase 3: Graph Construction (Week 9-12)
**ëª©í‘œ**: ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶• + 50,000ê°œ ë…¸ë“œ + 500,000ê°œ ì—£ì§€

```bash
# ì‘ì—… í•­ëª©
â–¡ ê´€ê³„ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
  - ì˜ë¯¸ì  ìœ ì‚¬ë„ (cosine similarity)
  - ì¸ê³¼ ê´€ê³„ ì¶”ë¡ 
  - ì€ìœ ì  ì—°ê²° ê°ì§€
â–¡ ê·¸ë˜í”„ DB êµ¬ì¶• (Neo4j ë˜ëŠ” NetworkX)
â–¡ ì»¤ë®¤ë‹ˆí‹° ê°ì§€ (Louvain)
â–¡ ê·¸ë˜í”„ ìµœì í™”
  - ì•½í•œ ì—£ì§€ ì œê±°
  - í´ëŸ¬ìŠ¤í„°ë§
  - ì¤‘ì‹¬ì„± ê³„ì‚°
â–¡ 50,000ê°œ ë…¸ë“œ ì™„ì„±
```

### Phase 4: Visualization & Integration (Week 13-16)
**ëª©í‘œ**: ì˜µì‹œë””ì–¸ ìŠ¤íƒ€ì¼ UI + IdeaConnect í†µí•©

```bash
# ì‘ì—… í•­ëª©
â–¡ í”„ë¡ íŠ¸ì—”ë“œ ê·¸ë˜í”„ ì‹œê°í™”
  - D3.js ë˜ëŠ” Cytoscape.js
  - Force-directed layout
  - ì¸í„°ë™í‹°ë¸Œ íƒìƒ‰
â–¡ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
  - ë‹¤ì°¨ì› ê²€ìƒ‰
  - ì»¨í…ìŠ¤íŠ¸ ì¸ì‹
  - ì¶”ì²œ ì‹œìŠ¤í…œ
â–¡ ì‚¬ìš©ì ë©”ëª¨ í†µí•©
  - ì–‘ë°©í–¥ ë§í¬
  - ìë™ ì—°ê²° ì œì•ˆ
â–¡ NAS ë°°í¬
```

### Phase 5: Intelligence & Iteration (Week 17+)
**ëª©í‘œ**: AI ê³ ë„í™” + ì§€ì†ì  ê°œì„ 

```bash
# ì‘ì—… í•­ëª©
â–¡ ê°œì¸í™” ì—”ì§„
  - ì‚¬ìš©ì í–‰ë™ í•™ìŠµ
  - ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •
â–¡ ì°½ë°œì  ë°œê²¬ ì•Œê³ ë¦¬ì¦˜
  - ì„¸ë Œë””í”¼í‹° ì£¼ì…
  - ì•½í•œ ì‹ í˜¸ ì¦í­
â–¡ ì „ë¬¸ê°€ íë ˆì´ì…˜ ì‹œìŠ¤í…œ
â–¡ ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°± ë£¨í”„
â–¡ A/B í…ŒìŠ¤íŠ¸ ë° ìµœì í™”
```

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

### ì–¸ì–´í•™
- Fillmore, C. J. (1982). *Frame Semantics*. Linguistics in the Morning Calm.
- Lakoff, G., & Johnson, M. (1980). *Metaphors We Live By*. University of Chicago Press.
- Palmer, M., et al. (2005). *The Proposition Bank*. Computational Linguistics.

### ì¸ì§€ì‹¬ë¦¬í•™
- Schank, R. C., & Abelson, R. P. (1977). *Scripts, Plans, Goals and Understanding*.
- Collins, A. M., & Loftus, E. F. (1975). *A Spreading-Activation Theory of Semantic Processing*.
- Petty, R. E., & Cacioppo, J. T. (1986). *The Elaboration Likelihood Model of Persuasion*.

### AI/NLP
- Reimers, N., & Gurevych, I. (2019). *Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks*.
- Bordes, A., et al. (2013). *Translating Embeddings for Modeling Multi-relational Data* (TransE).
- Pennington, J., et al. (2014). *GloVe: Global Vectors for Word Representation*.

### ì§€ì‹ ê·¸ë˜í”„
- Hogan, A., et al. (2021). *Knowledge Graphs*. ACM Computing Surveys.
- Wang, Q., et al. (2017). *Knowledge Graph Embedding: A Survey*.

---

## âœ… ì„±ê³µ ì§€í‘œ (KPIs)

### ì •ëŸ‰ì  ì§€í‘œ
- **ë…¸ë“œ ìˆ˜**: 50,000+ (ë‹¬ì„±ë¥  ì¸¡ì •)
- **ì—£ì§€ ìˆ˜**: 500,000+ (í‰ê·  10 ì—£ì§€/ë…¸ë“œ)
- **ì—£ì§€ í’ˆì§ˆ**: í‰ê·  ì‹ ë¢°ë„ > 0.7
- **ì„ë² ë”© í’ˆì§ˆ**: í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ > 0.6 (ê´€ë ¨ ë…¸ë“œ ê°„)
- **ê·¸ë˜í”„ ë°€ë„**: 0.001 ~ 0.01 (ë„ˆë¬´ í¬ì†Œí•˜ê±°ë‚˜ ì¡°ë°€í•˜ì§€ ì•Šê²Œ)

### ì •ì„±ì  ì§€í‘œ
- **ë©”íƒ€ë°ì´í„° ì™„ì„±ë„**: 80% ì´ìƒ ë…¸ë“œê°€ ëª¨ë“  ì°¨ì› ì£¼ì„ ë³´ìœ 
- **ì»¤ë®¤ë‹ˆí‹° êµ¬ì¡°**: ëª…í™•í•œ 10-20ê°œ ì£¼ì œ í´ëŸ¬ìŠ¤í„° í˜•ì„±
- **ë‹¤ì–‘ì„±**: 10ê°œ ì¹´í…Œê³ ë¦¬ì— ê· í˜•ì¡íŒ ë¶„í¬

### ì‚¬ìš©ì ê²½í—˜ ì§€í‘œ
- **ê²€ìƒ‰ ì •í™•ë„**: ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•´ ìƒìœ„ 5ê°œ ê²°ê³¼ ì¤‘ ìµœì†Œ 3ê°œ ê´€ë ¨ì„± ë†’ìŒ
- **ë°œê²¬ ë¹„ìœ¨**: ì‚¬ìš©ìê°€ ì˜ˆìƒí•˜ì§€ ëª»í•œ ìœ ìš©í•œ ì—°ê²°ì„ ì„¸ì…˜ë‹¹ í‰ê·  2ê°œ ì´ìƒ ë°œê²¬
- **ì²´ë¥˜ ì‹œê°„**: í‰ê·  ì„¸ì…˜ ì‹œê°„ > 10ë¶„ (ëª°ì…ë„)
- **ì €ì¥ë¥ **: íƒìƒ‰í•œ ë…¸ë“œ ì¤‘ 10% ì´ìƒì„ ì‚¬ìš©ìê°€ ì €ì¥
- **í†µí•©ë¥ **: ì‚¬ìš©ì ë©”ëª¨ì˜ 30% ì´ìƒì´ ë°ì´í„°ë² ì´ìŠ¤ ë…¸ë“œì™€ ì—°ê²°

---

## ğŸ¯ í•µì‹¬ ì°¨ë³„ì  ìš”ì•½

| ê¸°ì¡´ ì ‘ê·¼ | ê°œì„ ëœ ì ‘ê·¼ |
|---------|-----------|
| í‚¤ì›Œë“œ ë§¤ì¹­ | ë‹¤ì°¨ì› ì„ë² ë”© (ì˜ë¯¸Â·ê°ì •Â·ì‹¤ìš©) |
| ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ | ë‹¤ì¤‘ ìŠ¤í‚¤ë§ˆ + í”„ë ˆì„ |
| ì •ì  ê´€ê³„ | ë™ì Â·ê°€ì¤‘Â·ë§¥ë½ì  ê´€ê³„ |
| ê²€ìƒ‰ ì¤‘ì‹¬ | ë°œê²¬(discovery) ì¤‘ì‹¬ |
| ì¼ë¥ ì  ì¶”ì²œ | ê°œì¸í™”ëœ ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ |
| 2D ë¦¬ìŠ¤íŠ¸ | 3D ì§€ì‹ ê·¸ë˜í”„ ì‹œê°í™” |
| ì•Œê³ ë¦¬ì¦˜ë§Œ | ì•Œê³ ë¦¬ì¦˜ + ì „ë¬¸ê°€ + ì»¤ë®¤ë‹ˆí‹° |

---

**ì´ ê°€ì´ë“œëŠ” ë‹¨ìˆœí•œ ëª…ì–¸ ìˆ˜ì§‘ì„ ë„˜ì–´, ì‚¬ê³ ì˜ ì—°ê²°ë§ì„ êµ¬ì¶•í•˜ì—¬ ì§„ì •í•œ ì§€ì‹ ì°½ë°œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.**

**ì‘ì„±ì¼**: 2025-11-09  
**ë²„ì „**: 2.0 (Enhanced)  
**ì‘ì„± ê¸°ì¤€**: ì–¸ì–´í•™Â·ì¸ì§€ì‹¬ë¦¬í•™Â·AI í•™ì œê°„ í†µí•©
