# IdeaConnect v2.0 ì™„ë²½ ê°€ì´ë“œ
## ì´ë¡ ì  ê¹Šì´ + ì‹¤ìš©ì  êµ¬í˜„ + UX í˜ì‹ 

**ë²„ì „**: 2.0
**ì‘ì„±ì¼**: 2025-11-10
**ê¸°ì¤€**: ì–¸ì–´í•™Â·ì¸ì§€ì‹¬ë¦¬í•™Â·AI í•™ì œê°„ í†µí•© + ì‹¤ì „ êµ¬í˜„

---

# Part 1: ë¹„ì „ & ì´ë¡ ì  ê¸°ë°˜

## 1.1 ëª©í‘œ ì¬ì •ì˜

### ê¸°ì¡´ ëª©í‘œì˜ ë¬¸ì œì 

âŒ **ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ ì¤‘ì‹¬** â†’ ë§¥ë½ ì†ì‹¤
- "ìŠµê´€"ì´ë¼ëŠ” ë‹¨ì–´ë§Œ ì°¾ì•„ì„œ ì—°ê²°
- ê¹Šì€ ì˜ë¯¸ ì—°ê²° ë¶€ì¬
- ì‚¬ìš©ìê°€ ê¸°ëŒ€í•˜ì§€ ëª»í•œ ë°œê²¬ ì–´ë ¤ì›€

âŒ **ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘ì‹¬** â†’ ê°œë… ê°„ ê´€ê³„ ë¶€ì¬
- "ëª…ì–¸", "ì±…", "ì˜í™”"ë¡œë§Œ ë¶„ë¥˜
- ì•„ì´ë””ì–´ ê°„ ìœ ê¸°ì  ì—°ê²° ë¯¸í¡
- ì§€ì‹ì˜ ë„¤íŠ¸ì›Œí¬ê°€ ì•„ë‹Œ ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸

âŒ **ê²€ìƒ‰ ìµœì í™” ì¤‘ì‹¬** â†’ ë°œê²¬(discovery) ê²½í—˜ ë¶€ì¡±
- ê²€ìƒ‰í•˜ë©´ ë‚˜ì˜¤ëŠ” ê²ƒë§Œ ë³¼ ìˆ˜ ìˆìŒ
- ìš°ì—°í•œ ë°œê²¬(ì„¸ë Œë””í”¼í‹°) ë¶€ì¬
- ì°½ì˜ì  ì—°ê²° ê²½í—˜ ì œí•œ

### ìƒˆë¡œìš´ ë¹„ì „

> **"ì‚¬ê³ ì˜ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ì•„ì´ë””ì–´ ê°„ ìœ ê¸°ì  ì—°ê²°ê³¼ ì°½ë°œì  ë°œê²¬ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤"**

#### ì •ëŸ‰ì  ëª©í‘œ

| ì§€í‘œ | ëª©í‘œ | ì„¤ëª… |
|------|------|------|
| **ë…¸ë“œ(ì•„ì´ë””ì–´)** | 50,000ê°œ ì´ìƒ | ë‹¤ì–‘í•œ ì¶œì²˜ì˜ ê³ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ |
| **ì—£ì§€(ê´€ê³„)** | 500,000ê°œ ì´ìƒ | í‰ê·  ë…¸ë“œë‹¹ 10ê°œ ì—°ê²° |
| **ê´€ê³„ë§ êµ¬ì¡°** | ë‹¤ì¸µì  | ì˜ë¯¸ì , ê°ì •ì , ì‹¤ìš©ì , ì—­ì‚¬ì  |
| **ê²€ìƒ‰ ì •í™•ë„** | 85% ì´ìƒ | ìƒìœ„ 5ê°œ ê²°ê³¼ ì¤‘ 4ê°œ ì´ìƒ ê´€ë ¨ì„± ë†’ìŒ |

#### ì •ì„±ì  ëª©í‘œ

1. **ë§¥ë½ì  ìœ ì‚¬ë„**: í‘œë©´ì  í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì‹¬ì¸µ ì˜ë¯¸ ì—°ê²°
2. **ì°½ë°œì  ë°œê²¬**: ì˜ˆìƒì¹˜ ëª»í•œ ì•„ì´ë””ì–´ ê°„ ì—°ê²° ì§€ì›
3. **ì¸ì§€ ë¶€í•˜ ìµœì í™”**: ì •ë³´ ê³¼ë¶€í•˜ ì—†ì´ í†µì°° ì œê³µ
4. **ê°œì¸í™” ê°€ëŠ¥ì„±**: ì‚¬ìš©ì ì‚¬ê³  íŒ¨í„´ í•™ìŠµ ê¸°ë°˜

---

## 1.2 ì¸ì§€ì‹¬ë¦¬í•™ì  ì„¤ê³„

### ì›ë¦¬ 1: ìŠ¤í‚¤ë§ˆ ì´ë¡  (Schema Theory)

**í•µì‹¬ ê°œë…**: ì¸ê°„ì€ ê°œë…ì„ ë…ë¦½ëœ ì ì´ ì•„ë‹Œ, ì—°ê²°ëœ êµ¬ì¡°(ìŠ¤í‚¤ë§ˆ)ë¡œ ì €ì¥í•œë‹¤.

**ì°½ì‹œì**: Jean Piaget, Frederic Bartlett

**IdeaConnect ì ìš©**:
```typescript
interface SchemaMapping {
  schema_type: string;        // "ìŠµê´€ í˜•ì„± ìŠ¤í‚¤ë§ˆ"
  slot: string;               // "ê²°ê³¼"
  related_slots: {
    ì›ì¸: string[];           // ["ë°˜ë³µ", "ì‹¤ì²œ"]
    ë©”ì»¤ë‹ˆì¦˜: string[];       // ["ì‹ ê²½ê°€ì†Œì„±", "ìë™í™”"]
    ì‹œê°„ì„±: string[];         // ["ì¥ê¸°ì ", "ëˆ„ì ì "]
  };
}

// ì˜ˆì‹œ ë°ì´í„°
{
  id: "node_001",
  content: "We are what we repeatedly do. Excellence, then, is not an act, but a habit.",
  schema_mappings: [
    {
      schema_type: "ìŠµê´€ í˜•ì„± ìŠ¤í‚¤ë§ˆ",
      slot: "ê²°ê³¼",
      related_slots: {
        ì›ì¸: ["ë°˜ë³µ", "ì‹¤ì²œ"],
        ë©”ì»¤ë‹ˆì¦˜: ["ì‹ ê²½ê°€ì†Œì„±", "ìë™í™”"],
        ì‹œê°„ì„±: ["ì¥ê¸°ì ", "ëˆ„ì ì "]
      }
    }
  ]
}
```

**ì¹´í…Œê³ ë¦¬ â†’ ìŠ¤í‚¤ë§ˆ ë³€í™˜í‘œ**:

| ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ | ìŠ¤í‚¤ë§ˆ | í•˜ìœ„ ìŠ¤í‚¤ë§ˆ |
|-------------|--------|------------|
| ìŠµê´€ | í–‰ë™ ë³€í™” ìŠ¤í‚¤ë§ˆ | ìŠµê´€ í˜•ì„±, ìŠµê´€ ê¹¨ê¸°, ìë™í™” |
| ì„±ì¥ | ë°œë‹¬ ìŠ¤í‚¤ë§ˆ | í•™ìŠµ, ì ì‘, ì§„í™”, ê·¹ë³µ |
| ê´€ê³„ | ì‚¬íšŒì  ì¸ì§€ ìŠ¤í‚¤ë§ˆ | ê³µê°, ì†Œí†µ, ê°ˆë“±, ì‹ ë¢° |
| ì‹œê°„ | ì‹œê°„ ì¸ì‹ ìŠ¤í‚¤ë§ˆ | í˜„ì¬ ì¤‘ì‹¬, ë¯¸ë˜ ì§€í–¥, ê³¼ê±° ì„±ì°° |
| ëª©í‘œ | ë™ê¸° ìŠ¤í‚¤ë§ˆ | ë‚´ì¬ ë™ê¸°, ì™¸ì¬ ë™ê¸°, ìê¸°íš¨ëŠ¥ê° |

**êµ¬í˜„ íš¨ê³¼**:
- ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„  ê°œë…ì  ì—°ê²°
- ì‚¬ìš©ìê°€ "ìŠµê´€"ì„ ê²€ìƒ‰í•˜ë©´ "ì •ì²´ì„±", "ë°˜ë³µ", "ì‹œê°„" ë“± ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ë…¸ë“œ ìë™ ì—°ê²°
- ë” í’ë¶€í•œ íƒìƒ‰ ê²½í—˜

---

### ì›ë¦¬ 2: í™•ì‚° í™œì„±í™” ì´ë¡  (Spreading Activation)

**í•µì‹¬ ê°œë…**: í•˜ë‚˜ì˜ ê°œë…ì´ í™œì„±í™”ë˜ë©´ ê´€ë ¨ëœ ê°œë…ë“¤ì´ ì—°ì‡„ì ìœ¼ë¡œ í™œì„±í™”ëœë‹¤.

**ì°½ì‹œì**: Allan Collins, Elizabeth Loftus (1975)

**IdeaConnect ì ìš©**:
```javascript
// ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê´€ê³„ë§
{
  from: "ìŠµê´€",
  to: "ì •ì²´ì„±",
  edge_type: "ì¸ê³¼ê´€ê³„",
  weight: 0.87,              // ê°•í•œ ì—°ê²°
  activation_decay: 0.15,    // ì „íŒŒ ê°ì‡ ìœ¨
  bidirectional: true
}
```

**ê´€ê³„ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜**:

| ê´€ê³„ ìœ í˜• | ê°€ì¤‘ì¹˜ ë²”ìœ„ | ê°•ë„ | ì˜ˆì‹œ |
|----------|------------|------|------|
| **ì¸ê³¼ê´€ê³„** (A â†’ B) | 0.8-0.95 | ê°•í•¨ | "ë°˜ë³µ" â†’ "ìŠµê´€" |
| **ìœ ì‚¬ê´€ê³„** (A â‰ˆ B) | 0.6-0.8 | ì¤‘ê°„ | "ê¾¸ì¤€í•¨" â‰ˆ "ì¸ë‚´" |
| **ëŒ€ì¡°ê´€ê³„** (A â‰  B) | 0.5-0.7 | ì•½í•¨ | "ê³„íš" â‰  "ì¦‰í¥" |
| **ë§¥ë½ì ** | 0.4-0.6 | ì•½í•¨ | "ì•„ì¹¨" contextualâ†’ "ë£¨í‹´" |

**ì „íŒŒ ì•Œê³ ë¦¬ì¦˜**:
```python
def spreading_activation(start_node, max_depth=3, threshold=0.5):
    """
    ì‹œì‘ ë…¸ë“œë¡œë¶€í„° í™œì„±í™”ë¥¼ ì „íŒŒ
    """
    activation = {start_node: 1.0}
    queue = [(start_node, 1.0, 0)]  # (node, activation, depth)

    while queue:
        node, act, depth = queue.pop(0)

        if depth >= max_depth:
            continue

        # ì—°ê²°ëœ ë…¸ë“œë“¤ì—ê²Œ í™œì„±í™” ì „íŒŒ
        for edge in get_edges(node):
            new_activation = act * edge.weight * (1 - edge.activation_decay)

            if new_activation >= threshold:
                neighbor = edge.to

                # ê¸°ì¡´ í™œì„±í™”ì™€ ë¹„êµí•˜ì—¬ ë” ë†’ìœ¼ë©´ ì—…ë°ì´íŠ¸
                if neighbor not in activation or activation[neighbor] < new_activation:
                    activation[neighbor] = new_activation
                    queue.append((neighbor, new_activation, depth + 1))

    return activation
```

**ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ**:
```
ì‚¬ìš©ìê°€ "ìŠµê´€" ë©”ëª¨ ì‘ì„±
  â†“ (weight: 0.87)
"ì •ì²´ì„±" ì•„ì´ë””ì–´ í™œì„±í™”
  â†“ (weight: 0.75)
"ê°€ì¹˜ê´€" ì•„ì´ë””ì–´ í™œì„±í™”
  â†“ (weight: 0.68)
"ì„ íƒ" ì•„ì´ë””ì–´ í™œì„±í™”

â†’ ì‚¬ìš©ìëŠ” "ìŠµê´€ â†’ ì •ì²´ì„± â†’ ê°€ì¹˜ê´€ â†’ ì„ íƒ"ì˜ ì—°ê²° ê³ ë¦¬ ë°œê²¬!
```

---

### ì›ë¦¬ 3: ì •êµí™” ê°€ëŠ¥ì„± ëª¨ë¸ (Elaboration Likelihood Model)

**í•µì‹¬ ê°œë…**: ì •ë³´ ì²˜ë¦¬ ê¹Šì´ì— ë”°ë¼ ì¤‘ì‹¬ ê²½ë¡œ(ê¹Šì€ ì‚¬ê³ )ì™€ ì£¼ë³€ ê²½ë¡œ(íœ´ë¦¬ìŠ¤í‹±) êµ¬ë¶„

**ì°½ì‹œì**: Richard Petty, John Cacioppo (1986)

**IdeaConnect ì ìš©**: ì´ì¤‘ ê²€ìƒ‰ ê²½ë¡œ

```typescript
interface SearchResult {
  // ì¤‘ì‹¬ ê²½ë¡œ: ê¹Šì€ ì˜ë¯¸ ë§¤ì¹­ (ì‚¬ìš©ìê°€ ì§„ì§€í•˜ê²Œ íƒìƒ‰í•  ë•Œ)
  deep_matches: {
    content: string;
    semantic_similarity: number;  // 0.8+
    reasoning: string;             // ì™œ ì—°ê²°ë˜ëŠ”ì§€ ì„¤ëª…
    evidence: string[];            // ì—°ê²° ê·¼ê±°
  }[];

  // ì£¼ë³€ ê²½ë¡œ: ë¹ ë¥¸ ì—°ìƒ (ë¸Œë¼ìš°ì§• ëª¨ë“œ)
  quick_associations: {
    content: string;
    association_type: 'keyword' | 'emotion' | 'metaphor';
    strength: number;  // 0.5-0.7
    preview: string;   // í•œ ì¤„ ìš”ì•½
  }[];
}
```

**ì‚¬ìš©ì ìƒí™©ì— ë”°ë¥¸ ê²½ë¡œ ì„ íƒ**:

| ìƒí™© | ê²½ë¡œ | íŠ¹ì§• | UI í‘œì‹œ |
|------|------|------|---------|
| ë©”ëª¨ ì‘ì„± ì¤‘ | ì£¼ë³€ ê²½ë¡œ | ë¹ ë¥¸ íŒíŠ¸, ê°€ë²¼ìš´ ì˜ê° | ì‚¬ì´ë“œë°”ì— 3-5ê°œ ë¯¸ë¦¬ë³´ê¸° |
| "ì—°ê²° ì°¾ê¸°" í´ë¦­ | ì¤‘ì‹¬ ê²½ë¡œ | ê¹Šì€ ë¶„ì„, ìƒì„¸í•œ ì„¤ëª… | ì „ì²´ í˜ì´ì§€, ê·¼ê±° ì œì‹œ |
| ê·¸ë˜í”„ íƒìƒ‰ ì¤‘ | í˜¼í•© | ì£¼ë³€ìœ¼ë¡œ ì‹œì‘ â†’ í´ë¦­ ì‹œ ì¤‘ì‹¬ | í˜¸ë²„: ìš”ì•½ / í´ë¦­: ìƒì„¸ |

---

## 1.3 ì–¸ì–´í•™ì  ì„¤ê³„

### ì›ë¦¬ 1: í”„ë ˆì„ ì˜ë¯¸ë¡  (Frame Semantics)

**í•µì‹¬ ê°œë…**: ë‹¨ì–´ëŠ” í”„ë ˆì„(ìƒí™© êµ¬ì¡°) ë‚´ì—ì„œ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤.

**ì°½ì‹œì**: Charles Fillmore (1982)

**ì˜ˆì‹œ**: "êµ¬ë§¤" í”„ë ˆì„
```yaml
í”„ë ˆì„: ìƒì—…ì _ê±°ë˜
í•µì‹¬_ìš”ì†Œ:
  - êµ¬ë§¤ì (Buyer)
  - íŒë§¤ì (Seller)
  - ìƒí’ˆ (Goods)
  - ëŒ€ê°€ (Money)
  - ì‹œì  (Time)

ì—°ê²°_í”„ë ˆì„:
  - ì†Œìœ _ë³€ê²½
  - ê²½ì œ_êµí™˜
  - ì„ íƒ_í–‰ìœ„
```

**IdeaConnect ë°ì´í„° êµ¬ì¡° ì ìš©**:
```json
{
  "id": "quote_315",
  "content": "The best time to plant a tree was 20 years ago. The second best time is now.",
  "author": "Chinese Proverb",

  "linguistic": {
    "primary_frame": "ì‹œê°„ê³¼_í–‰ë™",
    "frame_elements": {
      "action": "ì‹¬ê¸° (ì‹ìˆ˜)",
      "optimal_time": "ê³¼ê±° (20ë…„ ì „)",
      "alternative_time": "í˜„ì¬",
      "implicit_message": "ì§€ê¸ˆ_ì‹œì‘í•˜ê¸°"
    },
    "frame_relations": [
      {
        "related_frame": "í›„íšŒì™€_íšŒë³µ",
        "relation": "inheritance"
      },
      {
        "related_frame": "ê¸°íšŒ_í¬ì°©",
        "relation": "subframe"
      }
    ]
  }
}
```

**í”„ë ˆì„ ê¸°ë°˜ ê²€ìƒ‰ì˜ ì¥ì **:
- "ë‚˜ë¬´ ì‹¬ê¸°"ë¥¼ ê²€ìƒ‰í•˜ì§€ ì•Šì•„ë„ "ì§€ê¸ˆ ì‹œì‘í•˜ê¸°" í”„ë ˆì„ìœ¼ë¡œ ì—°ê²°
- "í›„íšŒ"ì™€ "ê¸°íšŒ" ê°œë…ë„ ìë™ìœ¼ë¡œ ì—°ê²°
- ë§¥ë½ì  ì´í•´ ê°€ëŠ¥

---

### ì›ë¦¬ 2: ê°œë…ì  ì€ìœ  ì´ë¡  (Conceptual Metaphor Theory)

**í•µì‹¬ ê°œë…**: ì¶”ìƒì  ê°œë…ì€ êµ¬ì²´ì  ì€ìœ ë¡œ ì´í•´ëœë‹¤.

**ì°½ì‹œì**: George Lakoff, Mark Johnson (1980)

**í•µì‹¬ ì€ìœ  ì²´ê³„**:

#### ì€ìœ  1: "ì‹œê°„ì€ ìì›ì´ë‹¤"
```javascript
{
  system: "ì‹œê°„ì€_ìì›ì´ë‹¤",
  source_domain: "ë¬¼ì§ˆì _ìì›",
  target_domain: "ì‹œê°„",
  mappings: {
    spending: "ë³´ë‚´ë‹¤",
    saving: "ì•„ë¼ë‹¤",
    wasting: "ë‚­ë¹„í•˜ë‹¤",
    investing: "íˆ¬ìí•˜ë‹¤"
  },
  example_quotes: [
    "Time is money",
    "Don't waste your time",
    "Invest your time wisely"
  ]
}
```

#### ì€ìœ  2: "ì¸ìƒì€ ì—¬ì •ì´ë‹¤"
```javascript
{
  system: "ì¸ìƒì€_ì—¬ì •ì´ë‹¤",
  source_domain: "ë¬¼ë¦¬ì _ì—¬í–‰",
  target_domain: "ì¸ìƒ",
  mappings: {
    path: "ê¸¸/ê²½ë¡œ",
    obstacles: "ì¥ì• ë¬¼",
    destination: "ëª©í‘œ",
    companions: "ë™ë°˜ì",
    crossroads: "ì„ íƒì˜_ìˆœê°„"
  },
  example_quotes: [
    "Life is a journey, not a destination",
    "We're all on different paths",
    "Every setback is a setup for a comeback"
  ]
}
```

#### ì€ìœ  3: "ì•„ì´ë””ì–´ëŠ” ê±´ë¬¼ì´ë‹¤"
```javascript
{
  system: "ì•„ì´ë””ì–´ëŠ”_ê±´ë¬¼ì´ë‹¤",
  source_domain: "ê±´ì¶•",
  target_domain: "ì¶”ë¡ ",
  mappings: {
    foundation: "ê¸°ì´ˆ/ì „ì œ",
    structure: "ë…¼ë¦¬_êµ¬ì¡°",
    collapse: "ë…¼ë¦¬_ë¶•ê´´",
    support: "ê·¼ê±°"
  },
  example_quotes: [
    "Build your argument on solid foundations",
    "That theory doesn't hold up",
    "Strong evidence supports this claim"
  ]
}
```

**IdeaConnect ë°ì´í„°ì— ì€ìœ  íƒœê¹…**:
```json
{
  "content": "Build your dreams one brick at a time",
  "metaphor": {
    "system": "ëª©í‘œëŠ”_ê±´ë¬¼ì´ë‹¤",
    "elements": ["build", "brick", "one at a time"],
    "source_domain": "ê±´ì¶•",
    "target_domain": "ëª©í‘œ_ë‹¬ì„±",
    "related_metaphors": ["ì¸ìƒì€_ì—¬ì •ì´ë‹¤"]
  }
}
```

**ì€ìœ  ê¸°ë°˜ ì—°ê²°ì˜ í˜**:
- "ë²½ëŒ"ì„ ê²€ìƒ‰í•˜ì§€ ì•Šì•„ë„ "ìŠµê´€", "ê¾¸ì¤€í•¨"ê³¼ ì—°ê²°
- ì„œë¡œ ë‹¤ë¥¸ ì€ìœ  ì‹œìŠ¤í…œ ê°„ì˜ êµì°¨ ì—°ê²°
- ì°½ì˜ì  ì•„ì´ë””ì–´ ë°œê²¬

---

### ì›ë¦¬ 3: ì˜ë¯¸ ì—­í•  ì´ë¡  (Semantic Role Labeling)

**í•µì‹¬ ê°œë…**: ë¬¸ì¥ì˜ ì‹¬ì¸µ êµ¬ì¡°ë¥¼ í–‰ìœ„ì-í–‰ìœ„-ëŒ€ìƒìœ¼ë¡œ ë¶„í•´

**IdeaConnect ì ìš©**:
```python
{
  "content": "Courage is not the absence of fear, but the triumph over it.",
  "author": "Nelson Mandela",

  "semantic_roles": {
    "theme": "ìš©ê¸°",               # ì£¼ì œ
    "attribute": "ë‘ë ¤ì›€ì˜_ë¶€ì¬ê°€_ì•„ë‹˜",  # ì†ì„± (ë¶€ì •)
    "attribute_corrected": "ë‘ë ¤ì›€ì—_ëŒ€í•œ_ìŠ¹ë¦¬",  # ì‹¤ì œ ì†ì„±
    "implicit_agent": "ìš©ê¸°ìˆëŠ”_ì‚¬ëŒ"  # ì•”ë¬µì  í–‰ìœ„ì
  },

  "deep_structure": {
    "proposition": "ìš©ê¸° = ê·¹ë³µ(í–‰ìœ„ì, ë‘ë ¤ì›€)",
    "negation": "ìš©ê¸° â‰  ë¶€ì¬(ë‘ë ¤ì›€)"
  }
}
```

**ì˜ë¯¸ ì—­í•  ìë™ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤**:
```python
import spacy

nlp = spacy.load("en_core_web_trf")

def extract_semantic_roles(text):
    doc = nlp(text)

    roles = {
        "agents": [],      # í–‰ìœ„ì
        "patients": [],    # í”¼í–‰ìœ„ì
        "themes": [],      # ì£¼ì œ
        "instruments": [], # ë„êµ¬
        "locations": [],   # ì¥ì†Œ
        "times": []        # ì‹œê°„
    }

    for token in doc:
        if token.dep_ == "nsubj":
            roles["agents"].append(token.text)
        elif token.dep_ == "dobj":
            roles["patients"].append(token.text)
        elif token.dep_ == "attr":
            roles["themes"].append(token.text)

    return roles
```

---

## 1.4 AI/NLP ê¸°ìˆ  ìŠ¤íƒ

### ê¸°ìˆ  1: ì„ë² ë”© ë²¡í„° ê³µê°„ (Embedding Space)

**ì‚¬ìš© ëª¨ë¸**: Sentence Transformers / OpenAI Embeddings

**ë‹¤ì¤‘ ì„ë² ë”© ì „ëµ**:
```python
from sentence_transformers import SentenceTransformer

class MultiEmbedding:
    def __init__(self):
        # 1. ì˜ë¯¸ì  ì„ë² ë”© (semantic)
        self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')

        # 2. ê°ì •ì  ì„ë² ë”© (emotional)
        self.emotion_model = SentenceTransformer('j-hartmann/emotion-english-distilroberta-base')

        # 3. ì˜ë„ ì„ë² ë”© (pragmatic)
        self.intent_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

    def encode(self, text):
        return {
            'semantic': self.semantic_model.encode(text),    # 768-dim
            'emotional': self.emotion_model.encode(text),    # 768-dim
            'pragmatic': self.intent_model.encode(text)      # 768-dim
        }
```

**ë‹¤ì°¨ì› ìœ ì‚¬ë„ ê³„ì‚°**:
```python
from sklearn.metrics.pairwise import cosine_similarity

def multi_dimensional_similarity(vec1, vec2, weights):
    """
    weights ì˜ˆì‹œ:
    {
        'semantic': 0.5,    # ì˜ë¯¸ì  ìœ ì‚¬ë„ì— 50% ê°€ì¤‘ì¹˜
        'emotional': 0.3,   # ê°ì •ì  ìœ ì‚¬ë„ì— 30% ê°€ì¤‘ì¹˜
        'pragmatic': 0.2    # ì‹¤ìš©ì  ìœ ì‚¬ë„ì— 20% ê°€ì¤‘ì¹˜
    }
    """
    similarities = {}

    for dimension in ['semantic', 'emotional', 'pragmatic']:
        cos_sim = cosine_similarity(
            vec1[dimension].reshape(1, -1),
            vec2[dimension].reshape(1, -1)
        )[0][0]
        similarities[dimension] = cos_sim

    # ê°€ì¤‘ í‰ê· 
    weighted_sim = sum(
        similarities[dim] * weights[dim]
        for dim in weights
    )

    return weighted_sim, similarities
```

**ë°ì´í„° ì €ì¥ êµ¬ì¡°**:
```json
{
  "id": "node_001",
  "content": "We are what we repeatedly do.",
  "embeddings": {
    "semantic_v": [0.123, -0.456, 0.789, ...],   // 768 dim
    "emotional_v": [0.234, 0.567, -0.123, ...],  // 768 dim
    "pragmatic_v": [-0.345, 0.678, 0.234, ...]   // 768 dim
  },
  "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
  "version": "2.0"
}
```

---

### ê¸°ìˆ  2: ì§€ì‹ ê·¸ë˜í”„ ì„ë² ë”© (Knowledge Graph Embedding)

**ì‚¬ìš© ëª¨ë¸**: TransE, ComplEx, RotatE

**TransE ëª¨ë¸ ê°œë…**:
```
h + r â‰ˆ t
(head entity) + (relation) â‰ˆ (tail entity)

ì˜ˆì‹œ:
"ìŠµê´€" + "ê²°ê³¼ëŠ”" â‰ˆ "ì •ì²´ì„±"
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
import numpy as np

class TransE:
    """
    TransE: Translating Embeddings for Knowledge Graphs
    """

    def __init__(self, entity_dim=128, relation_dim=128):
        self.entity_embeddings = {}
        self.relation_embeddings = {}
        self.entity_dim = entity_dim
        self.relation_dim = relation_dim

    def train(self, triples, epochs=100, learning_rate=0.01):
        """
        triples: [("ìŠµê´€", "leads_to", "ì •ì²´ì„±"), ...]
        """

        # ì„ë² ë”© ì´ˆê¸°í™”
        entities = set()
        relations = set()

        for (h, r, t) in triples:
            entities.add(h)
            entities.add(t)
            relations.add(r)

        for entity in entities:
            self.entity_embeddings[entity] = np.random.randn(self.entity_dim)

        for relation in relations:
            self.relation_embeddings[relation] = np.random.randn(self.relation_dim)

        # í•™ìŠµ
        for epoch in range(epochs):
            for (h, r, t) in triples:
                h_vec = self.entity_embeddings[h]
                r_vec = self.relation_embeddings[r]
                t_vec = self.entity_embeddings[t]

                # ì†ì‹¤: ||h + r - t||
                loss = np.linalg.norm(h_vec + r_vec - t_vec)

                # ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ (ê°„ë‹¨íˆ í‘œí˜„)
                grad = (h_vec + r_vec - t_vec) / (loss + 1e-8)

                self.entity_embeddings[h] -= learning_rate * grad
                self.relation_embeddings[r] -= learning_rate * grad
                self.entity_embeddings[t] += learning_rate * grad

    def predict_tail(self, head, relation):
        """ì£¼ì–´ì§„ (head, relation)ìœ¼ë¡œ tail ì˜ˆì¸¡"""
        h_vec = self.entity_embeddings[head]
        r_vec = self.relation_embeddings[relation]

        predicted_t = h_vec + r_vec

        # ê°€ì¥ ê°€ê¹Œìš´ entity ì°¾ê¸°
        min_distance = float('inf')
        best_entity = None

        for entity, vec in self.entity_embeddings.items():
            distance = np.linalg.norm(predicted_t - vec)
            if distance < min_distance:
                min_distance = distance
                best_entity = entity

        return best_entity, min_distance

# ì‚¬ìš© ì˜ˆì‹œ
model = TransE()
triples = [
    ("ìŠµê´€", "ê²°ê³¼ëŠ”", "ì •ì²´ì„±"),
    ("ë°˜ë³µ", "leads_to", "ìŠµê´€"),
    ("ì‹œê°„", "enables", "ë³€í™”"),
    ("ì˜ì§€", "requires", "ë™ê¸°")
]

model.train(triples)

# "ìŠµê´€" + "ê²°ê³¼ëŠ”" â†’ ?
result, confidence = model.predict_tail("ìŠµê´€", "ê²°ê³¼ëŠ”")
print(f"ì˜ˆì¸¡: {result}, ì‹ ë¢°ë„: {1 - confidence}")  # â†’ "ì •ì²´ì„±"
```

---

### ê¸°ìˆ  3: ê´€ê³„ ì¶”ì¶œ (Relation Extraction)

**ê´€ê³„ ì˜¨í†¨ë¡œì§€ (Ontology)**:
```yaml
ê´€ê³„_ì²´ê³„:
  ì¸ê³¼_ê´€ê³„:
    - causes: Aê°€ Bë¥¼ ì•¼ê¸°í•¨
    - enables: Aê°€ Bë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨
    - prevents: Aê°€ Bë¥¼ ë§‰ìŒ
    - requires: Aê°€ Bë¥¼ í•„ìš”ë¡œ í•¨

  êµ¬ì¡°_ê´€ê³„:
    - part_of: AëŠ” Bì˜ ë¶€ë¶„
    - instance_of: AëŠ” Bì˜ ì‚¬ë¡€
    - contrasts_with: AëŠ” Bì™€ ëŒ€ì¡°ë¨

  ì‹œê°„_ê´€ê³„:
    - precedes: Aê°€ Bë³´ë‹¤ ë¨¼ì €
    - follows: Aê°€ Bë¥¼ ë”°ë¦„
    - during: AëŠ” B ë™ì•ˆ

  ì˜ë¯¸_ê´€ê³„:
    - similar_to: ìœ ì‚¬í•¨
    - analogous_to: ìœ ì¶” ê°€ëŠ¥
    - metaphor_of: ì€ìœ  ê´€ê³„

  ê°ì •_ê´€ê³„:
    - evokes: Aê°€ B ê°ì •ì„ ìœ ë°œ
    - expressed_by: AëŠ” Bë¡œ í‘œí˜„ë¨
```

**ìë™ ê´€ê³„ ì¶”ì¶œ êµ¬í˜„**:
```python
import spacy
from transformers import pipeline

nlp = spacy.load("en_core_web_trf")

def extract_relations(quote1, quote2):
    """ë‘ ëª…ì–¸ ê°„ ê´€ê³„ ìë™ ì¶”ì¶œ"""

    doc1 = nlp(quote1.content)
    doc2 = nlp(quote2.content)

    relations = []

    # 1. ê³µí†µ ê°œë… ì¶”ì¶œ
    concepts1 = [ent.text for ent in doc1.ents]
    concepts2 = [ent.text for ent in doc2.ents]
    shared = set(concepts1) & set(concepts2)

    # 2. ì˜ë¯¸ì  ìœ ì‚¬ë„
    similarity = doc1.similarity(doc2)

    if similarity > 0.8:
        relations.append({
            "type": "similar_to",
            "strength": similarity,
            "evidence": f"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ {similarity:.2f}"
        })

    # 3. ì¸ê³¼ ê´€ê³„ ë§ˆì»¤ ê°ì§€
    causal_markers = ["because", "therefore", "thus", "leads to", "results in"]

    if any(marker in quote1.content.lower() for marker in causal_markers):
        if any(marker in quote2.content.lower() for marker in causal_markers):
            relations.append({
                "type": "causal_chain",
                "strength": 0.7,
                "evidence": "ì¸ê³¼ ê´€ê³„ ë§ˆì»¤ ë°œê²¬"
            })

    # 4. ëŒ€ì¡° ê´€ê³„ ë§ˆì»¤
    contrast_markers = ["but", "however", "although", "while", "whereas"]

    if any(marker in quote1.content.lower() for marker in contrast_markers):
        relations.append({
            "type": "contrasts_with",
            "strength": 0.6,
            "evidence": "ëŒ€ì¡° ê´€ê³„ ë§ˆì»¤ ë°œê²¬"
        })

    return relations
```

---

## 1.5 ì´ë¡ ì  ê¸°ë°˜ ìš”ì•½

### í•µì‹¬ ì›ë¦¬ í†µí•©

| í•™ë¬¸ ë¶„ì•¼ | í•µì‹¬ ì´ë¡  | IdeaConnect ì ìš© | íš¨ê³¼ |
|---------|---------|----------------|------|
| **ì¸ì§€ì‹¬ë¦¬í•™** | ìŠ¤í‚¤ë§ˆ ì´ë¡  | ê°œë…ì˜ êµ¬ì¡°í™”ëœ ì €ì¥ | ë§¥ë½ì  ì—°ê²° |
| **ì¸ì§€ì‹¬ë¦¬í•™** | í™•ì‚° í™œì„±í™” | ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì „íŒŒ | ì—°ì‡„ì  ë°œê²¬ |
| **ì¸ì§€ì‹¬ë¦¬í•™** | ELM | ì´ì¤‘ ê²€ìƒ‰ ê²½ë¡œ | ìƒí™©ë³„ ìµœì í™” |
| **ì–¸ì–´í•™** | í”„ë ˆì„ ì˜ë¯¸ë¡  | ìƒí™© êµ¬ì¡° ë§¤í•‘ | ê¹Šì€ ì´í•´ |
| **ì–¸ì–´í•™** | ê°œë…ì  ì€ìœ  | ì€ìœ  ì‹œìŠ¤í…œ íƒœê¹… | ì°½ì˜ì  ì—°ê²° |
| **ì–¸ì–´í•™** | ì˜ë¯¸ ì—­í•  | ì‹¬ì¸µ êµ¬ì¡° ë¶„ì„ | ì •í™•í•œ ê´€ê³„ |
| **AI/NLP** | ì„ë² ë”© ê³µê°„ | ë‹¤ì°¨ì› ë²¡í„° | ìˆ˜ì¹˜ì  ìœ ì‚¬ë„ |
| **AI/NLP** | ì§€ì‹ ê·¸ë˜í”„ ì„ë² ë”© | TransE ëª¨ë¸ | ê´€ê³„ ì˜ˆì¸¡ |
| **AI/NLP** | ê´€ê³„ ì¶”ì¶œ | ìë™ ì˜¨í†¨ë¡œì§€ | ëŒ€ê·œëª¨ ì²˜ë¦¬ |

### ì°¨ë³„í™” í¬ì¸íŠ¸

**ê¸°ì¡´ ì ‘ê·¼ vs IdeaConnect v2.0:**

| í•­ëª© | ê¸°ì¡´ | IdeaConnect v2.0 |
|------|------|-----------------|
| ê²€ìƒ‰ ë°©ì‹ | í‚¤ì›Œë“œ ë§¤ì¹­ | ë‹¤ì°¨ì› ì„ë² ë”© (ì˜ë¯¸Â·ê°ì •Â·ì‹¤ìš©) |
| ë¶„ë¥˜ | ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ | ë‹¤ì¤‘ ìŠ¤í‚¤ë§ˆ + í”„ë ˆì„ |
| ê´€ê³„ | ì •ì  | ë™ì Â·ê°€ì¤‘Â·ë§¥ë½ì  |
| ì‚¬ìš©ì ê²½í—˜ | ê²€ìƒ‰ ì¤‘ì‹¬ | ë°œê²¬(discovery) ì¤‘ì‹¬ |
| ì¶”ì²œ | ì¼ë¥ ì  | ê°œì¸í™”Â·ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ |
| ì‹œê°í™” | 2D ë¦¬ìŠ¤íŠ¸ | 3D ì§€ì‹ ê·¸ë˜í”„ |
| í’ˆì§ˆ ê´€ë¦¬ | ì•Œê³ ë¦¬ì¦˜ë§Œ | ì•Œê³ ë¦¬ì¦˜ + ì „ë¬¸ê°€ + ì»¤ë®¤ë‹ˆí‹° |

---

# Part 2: ë°ì´í„° ì•„í‚¤í…ì²˜

## 2.1 í–¥ìƒëœ ë…¸ë“œ(Node) êµ¬ì¡°

### ë‹¤ì¸µì  í‘œí˜„ ì‹œìŠ¤í…œ

**ì„¤ê³„ ì² í•™**: í•˜ë‚˜ì˜ ì•„ì´ë””ì–´ë¥¼ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ë¶„ì„í•˜ê³  ì €ì¥

```typescript
interface IdeaNode {
  // ===== ê¸°ë³¸ ì‹ë³„ ì •ë³´ =====
  id: string;                    // UUID
  content: string;               // ì›ë¬¸ (ì˜ì–´)
  content_ko?: string;           // ë²ˆì—­ (í•œêµ­ì–´)
  created_at: Date;
  updated_at: Date;

  // ===== ì¶œì²˜ ë©”íƒ€ë°ì´í„° =====
  source: {
    author: string;              // ì €ì/ì¸ë¬¼
    author_ko?: string;          // ì €ì í•œêµ­ì–´ëª…
    work?: string;               // ì‘í’ˆëª…
    work_ko?: string;
    year?: number;               // ì—°ë„
    url?: string;                // ì›¹ ì¶œì²˜
    isbn?: string;               // ì±…
    doi?: string;                // ë…¼ë¬¸
    imdb_id?: string;            // ì˜í™”
    verified: boolean;           // ì¶œì²˜ ê²€ì¦ ì—¬ë¶€
  };

  // ===== ì–¸ì–´í•™ì  ë¶„ì„ =====
  linguistic: {
    // í”„ë ˆì„ ì˜ë¯¸ë¡ 
    primary_frame: string;       // "ì‹œê°„ê³¼_í–‰ë™"
    frame_elements: Record<string, string>;
    related_frames: {
      frame: string;
      relation: 'inheritance' | 'subframe' | 'uses' | 'perspective';
    }[];

    // ì€ìœ  ë¶„ì„
    metaphors: {
      system: string;            // "ì‹œê°„ì€_ìì›ì´ë‹¤"
      elements: string[];        // ["spending", "saving"]
      source_domain: string;     // "ë¬¼ì§ˆì _ìì›"
      target_domain: string;     // "ì‹œê°„"
      strength: number;          // 0.0-1.0
    }[];

    // ì˜ë¯¸ ì—­í• 
    semantic_roles: {
      theme?: string;            // ì£¼ì œ
      agent?: string;            // í–‰ìœ„ì
      patient?: string;          // í”¼í–‰ìœ„ì
      instrument?: string;       // ë„êµ¬
      location?: string;         // ì¥ì†Œ
      time?: string;             // ì‹œê°„
    };

    // í™”í–‰ ì´ë¡  (Speech Act)
    speech_act: 'assertive' | 'directive' | 'commissive' | 'expressive' | 'declarative';

    // ë¶€ì • í‘œí˜„ ë¶„ì„
    negation?: {
      has_negation: boolean;
      negated_concept: string;
      affirmative_alternative?: string;
    };
  };

  // ===== ì¸ì§€ì‹¬ë¦¬í•™ì  ë¶„ì„ =====
  cognitive: {
    // ìŠ¤í‚¤ë§ˆ ë§¤í•‘
    schemas: {
      type: string;              // "ìŠµê´€ í˜•ì„± ìŠ¤í‚¤ë§ˆ"
      slot: string;              // "ê²°ê³¼"
      related_slots: Record<string, string[]>;
      activation_strength: number; // 0.0-1.0
    }[];

    // ì •ë³´ ì²˜ë¦¬ ìˆ˜ì¤€
    processing_level: 'surface' | 'semantic' | 'pragmatic';

    // ì¸ì§€ ë¶€í•˜
    cognitive_load: {
      level: 'low' | 'medium' | 'high';
      complexity_score: number;  // 0-100
      abstractness: number;      // 0.0-1.0 (êµ¬ì²´ì  vs ì¶”ìƒì )
    };

    // ê¸°ì–µ ì¸ì¶œ ë‹¨ì„œ
    retrieval_cues: string[];    // ["ìŠµê´€", "ë°˜ë³µ", "ì •ì²´ì„±"]

    // ì •êµí™” ìˆ˜ì¤€
    elaboration: {
      level: 'basic' | 'intermediate' | 'advanced';
      requires_context: boolean;
    };
  };

  // ===== ê°ì •/íƒœë„ ë¶„ì„ =====
  affective: {
    // ê°ì • ë²¡í„° (Plutchikì˜ 8ê°€ì§€ ê¸°ë³¸ ê°ì •)
    emotions: {
      joy: number;               // 0.0-1.0
      trust: number;
      fear: number;
      surprise: number;
      sadness: number;
      disgust: number;
      anger: number;
      anticipation: number;
    };

    // ê°ì •ê°€ (Valence): ê¸ì •/ë¶€ì •
    valence: number;             // -1.0 (ë§¤ìš° ë¶€ì •) ~ +1.0 (ë§¤ìš° ê¸ì •)

    // ê°ì„±ë„ (Arousal): ì°¨ë¶„í•¨/í¥ë¶„
    arousal: number;             // 0.0 (ì°¨ë¶„) ~ 1.0 (í¥ë¶„)

    // ì§€ë°°ì„± (Dominance): í†µì œê°
    dominance: number;           // 0.0 (ìˆ˜ë™ì ) ~ 1.0 (ì§€ë°°ì )

    // ê°ì • ê°•ë„
    intensity: number;           // 0.0-1.0

    // ì£¼ìš” ê°ì • (ìë™ ê³„ì‚°)
    primary_emotion: string;     // "í¬ë§", "ë™ê¸°ë¶€ì—¬", "ì„±ì°°" ë“±
  };

  // ===== ì‹¤ìš©ì  ì°¨ì› =====
  pragmatic: {
    // ì ìš© ê°€ëŠ¥í•œ ìƒí™©/ë§¥ë½
    applicable_contexts: string[]; // ["ìê¸°ê³„ë°œ", "ìŠµê´€ í˜•ì„±", "ë™ê¸°ë¶€ì—¬"]

    // í–‰ë™ ìœ ë„ì„± (Affordance)
    action_tendencies: string[]; // ["ë°˜ë³µ ì‹¤ì²œ", "ìê¸° ì„±ì°°", "ëª©í‘œ ì„¤ì •"]

    // ì‹¤ì²œ ë‚œì´ë„
    implementation: {
      difficulty: 'easy' | 'medium' | 'hard';
      time_required: 'immediate' | 'days' | 'weeks' | 'months' | 'years';
      resources_needed: string[];
    };

    // ì‹œê°„ ì§€í‰
    time_horizon: 'immediate' | 'short-term' | 'long-term' | 'lifelong';

    // ëŒ€ìƒ ì²­ì¤‘
    target_audience: string[];   // ["í•™ìƒ", "ì§ì¥ì¸", "ì°½ì—…ê°€", "ì¼ë°˜"]
  };

  // ===== ë²¡í„° ì„ë² ë”© =====
  embeddings: {
    semantic: number[];          // 768-dim (ì˜ë¯¸ì  ìœ ì‚¬ë„)
    emotional: number[];         // 768-dim (ê°ì •ì  ìœ ì‚¬ë„)
    pragmatic: number[];         // 768-dim (ì‹¤ìš©ì  ìœ ì‚¬ë„)
    kg_embedding?: number[];     // 128-dim (ì§€ì‹ ê·¸ë˜í”„)

    // ì„ë² ë”© ë©”íƒ€ì •ë³´
    model_version: string;       // "all-MiniLM-L6-v2"
    generated_at: Date;
  };

  // ===== ë¶„ë¥˜ ì •ë³´ =====
  classification: {
    // ê¸°ë³¸ ì¹´í…Œê³ ë¦¬
    primary_category: IdeaType;  // "famous-quote", "book", etc.
    secondary_categories: IdeaType[];

    // ì£¼ì œ íƒœê·¸
    topics: string[];            // ["ìŠµê´€", "ì„±ì¥", "ì‹œê°„ê´€ë¦¬"]

    // í‚¤ì›Œë“œ (ê²€ìƒ‰ìš©)
    keywords: string[];          // ìë™ ì¶”ì¶œ + ìˆ˜ë™ íë ˆì´ì…˜

    // ë‚œì´ë„
    difficulty_level: 'beginner' | 'intermediate' | 'advanced';
  };

  // ===== í’ˆì§ˆ & í†µê³„ =====
  quality: {
    // ìë™ í’ˆì§ˆ ì ìˆ˜
    auto_score: number;          // 0-100

    // ì „ë¬¸ê°€ íë ˆì´ì…˜
    curated: boolean;
    curator_notes?: string;

    // ì™„ì„±ë„
    completeness: {
      has_embeddings: boolean;
      has_linguistic: boolean;
      has_cognitive: boolean;
      has_affective: boolean;
      overall: number;           // 0-100
    };
  };

  stats: {
    view_count: number;
    connection_count: number;    // ëª‡ ê°œì˜ ì—£ì§€ì™€ ì—°ê²°ë˜ì–´ ìˆëŠ”ê°€
    user_saved_count: number;    // ëª‡ ëª…ì´ ì €ì¥í–ˆëŠ”ê°€
    avg_rating: number;          // 0-5
    last_accessed: Date;
  };
}

// ì•„ì´ë””ì–´ íƒ€ì… ì •ì˜
type IdeaType =
  | 'famous-quote'
  | 'book'
  | 'proverb'
  | 'movie'
  | 'drama'
  | 'animation'
  | 'academic'
  | 'web'
  | 'essay'
  | 'poem';
```

### ë…¸ë“œ êµ¬ì¡° ì„¤ê³„ ì˜ë„

| ì„¹ì…˜ | ëª©ì  | í™œìš© |
|------|------|------|
| **ê¸°ë³¸ ì‹ë³„** | ê³ ìœ ì„±, ë²„ì „ ê´€ë¦¬ | CRUD ì‘ì—… |
| **ì¶œì²˜ ë©”íƒ€ë°ì´í„°** | ì‹ ë¢°ì„±, ì¶”ì ì„± | ê²€ì¦, ì¸ìš© |
| **ì–¸ì–´í•™ì  ë¶„ì„** | ê¹Šì€ ì˜ë¯¸ ì´í•´ | í”„ë ˆì„ ê¸°ë°˜ ê²€ìƒ‰, ì€ìœ  ì—°ê²° |
| **ì¸ì§€ì‹¬ë¦¬í•™ì  ë¶„ì„** | ì‚¬ê³  êµ¬ì¡° íŒŒì•… | ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì—°ê²°, í™œì„±í™” ì „íŒŒ |
| **ê°ì •/íƒœë„ ë¶„ì„** | ê°ì •ì  ê³µëª… | ê°ì • ê¸°ë°˜ ì¶”ì²œ, ë¬´ë“œë³„ íƒìƒ‰ |
| **ì‹¤ìš©ì  ì°¨ì›** | ì ìš© ê°€ëŠ¥ì„± | ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì¶”ì²œ |
| **ë²¡í„° ì„ë² ë”©** | ìˆ˜ì¹˜ì  ìœ ì‚¬ë„ | ë¹ ë¥¸ ê²€ìƒ‰, í´ëŸ¬ìŠ¤í„°ë§ |
| **ë¶„ë¥˜ ì •ë³´** | ì¡°ì§í™” | í•„í„°ë§, íƒìƒ‰ |
| **í’ˆì§ˆ & í†µê³„** | ì‹ ë¢°ì„±, ì¸ê¸°ë„ | ë­í‚¹, íë ˆì´ì…˜ |

---

## 2.2 ë‹¤ì°¨ì› ì—£ì§€(Edge) êµ¬ì¡°

### ê´€ê³„ì˜ ë³µì¡ì„± í‘œí˜„

**ì„¤ê³„ ì² í•™**: ë‘ ì•„ì´ë””ì–´ ê°„ì˜ ê´€ê³„ëŠ” ë‹¨ìˆœí•œ "ì—°ê²°ë¨"ì´ ì•„ë‹Œ ë‹¤ì¸µì  ì˜ë¯¸

```typescript
interface IdeaEdge {
  // ===== ê¸°ë³¸ ì‹ë³„ =====
  id: string;                    // UUID
  from: string;                  // ì¶œë°œ ë…¸ë“œ ID
  to: string;                    // ë„ì°© ë…¸ë“œ ID
  created_at: Date;

  // ===== ê´€ê³„ ìœ í˜• =====
  relation_type: RelationType;

  // ===== ê´€ê³„ ê°•ë„ =====
  strength: number;              // 0.0-1.0 (ì¢…í•© ê°•ë„)

  // ===== ì°¨ì›ë³„ ì ìˆ˜ =====
  dimensions: {
    semantic_similarity: number;     // ì˜ë¯¸ì  ìœ ì‚¬ì„± (0-1)
    emotional_resonance: number;     // ê°ì •ì  ê³µëª… (0-1)
    pragmatic_alignment: number;     // ì‹¤ìš©ì  ì •ë ¬ (0-1)
    metaphorical_connection: number; // ì€ìœ ì  ì—°ê²° (0-1)
    causal_strength: number;         // ì¸ê³¼ ê´€ê³„ ê°•ë„ (0-1)
    temporal_proximity: number;      // ì‹œê°„ì  ê·¼ì ‘ì„± (0-1)
  };

  // ===== ê´€ê³„ ì„¤ëª… =====
  reasoning: {
    automatic: string;           // AI ìë™ ìƒì„±
    curated?: string;            // íë ˆì´í„° ìˆ˜ë™ ì‘ì„±
    evidence: string[];          // ê·¼ê±° ë¦¬ìŠ¤íŠ¸
  };

  // ===== ì–‘ë°©í–¥ì„± =====
  bidirectional: boolean;        // ì–‘ë°©í–¥ ê´€ê³„ì¸ê°€?
  reverse_relation?: RelationType; // ì—­ë°©í–¥ ê´€ê³„ ìœ í˜•

  // ===== ì»¨í…ìŠ¤íŠ¸ ì˜ì¡´ì„± =====
  context_dependent: boolean;    // íŠ¹ì • ë§¥ë½ì—ì„œë§Œ ìœ íš¨í•œê°€?
  contexts?: string[];           // ["ìê¸°ê³„ë°œ", "ë¦¬ë”ì‹­"]

  // ===== ì‹ ë¢°ë„ & ì¶œì²˜ =====
  confidence: number;            // 0.0-1.0
  source: 'algorithm' | 'expert' | 'community' | 'user';

  // ===== í™œì„±í™” ì´ë ¥ =====
  activation: {
    count: number;               // ëª‡ ë²ˆ í™œì„±í™”ë˜ì—ˆëŠ”ê°€
    last_activated: Date;
    decay_rate: number;          // í™•ì‚° í™œì„±í™” ê°ì‡ ìœ¨
  };

  // ===== ê²€ì¦ & í’ˆì§ˆ =====
  verified: boolean;             // ì „ë¬¸ê°€ ê²€ì¦ ì—¬ë¶€
  quality_score: number;         // 0-100

  // ===== ë©”íƒ€ì •ë³´ =====
  version: string;
  notes?: string;
}

// ê´€ê³„ ìœ í˜• ì˜¨í†¨ë¡œì§€
type RelationType =
  // === ì˜ë¯¸ì  ê´€ê³„ ===
  | 'similar_to'              // ìœ ì‚¬í•¨
  | 'opposite_to'             // ë°˜ëŒ€ë¨
  | 'part_of'                 // ë¶€ë¶„-ì „ì²´
  | 'example_of'              // ì‚¬ë¡€
  | 'generalizes_to'          // ì¼ë°˜í™”
  | 'specializes_to'          // íŠ¹ìˆ˜í™”

  // === ì¸ê³¼ì  ê´€ê³„ ===
  | 'causes'                  // Aê°€ Bë¥¼ ì•¼ê¸°
  | 'enables'                 // Aê°€ Bë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨
  | 'prevents'                // Aê°€ Bë¥¼ ë§‰ìŒ
  | 'requires'                // Aê°€ Bë¥¼ í•„ìš”ë¡œ í•¨
  | 'contributes_to'          // Aê°€ Bì— ê¸°ì—¬

  // === ì‹œê°„ì  ê´€ê³„ ===
  | 'precedes'                // Aê°€ Bë³´ë‹¤ ë¨¼ì €
  | 'follows'                 // Aê°€ Bë¥¼ ë”°ë¦„
  | 'concurrent_with'         // Aì™€ Bê°€ ë™ì‹œ

  // === ë…¼ë¦¬ì  ê´€ê³„ ===
  | 'supports'                // Aê°€ Bë¥¼ ì§€ì§€
  | 'contradicts'             // Aê°€ Bì™€ ëª¨ìˆœ
  | 'refines'                 // Aê°€ Bë¥¼ ì •ì œ
  | 'extends'                 // Aê°€ Bë¥¼ í™•ì¥
  | 'implies'                 // Aê°€ Bë¥¼ í•¨ì˜

  // === ì€ìœ ì  ê´€ê³„ ===
  | 'metaphor_of'             // AëŠ” Bì˜ ì€ìœ 
  | 'analogy_to'              // AëŠ” Bì™€ ìœ ì¶”

  // === ê°ì •ì  ê´€ê³„ ===
  | 'evokes_same_emotion'     // ê°™ì€ ê°ì • ìœ ë°œ
  | 'contrasting_emotion'     // ëŒ€ì¡°ë˜ëŠ” ê°ì •

  // === ì‹¤ìš©ì  ê´€ê³„ ===
  | 'implements_same_principle' // ê°™ì€ ì›ë¦¬ êµ¬í˜„
  | 'alternative_approach'    // ëŒ€ì•ˆì  ì ‘ê·¼
  | 'complements'             // ë³´ì™„ ê´€ê³„

  // === êµ¬ì¡°ì  ê´€ê³„ ===
  | 'belongs_to_category'     // ì¹´í…Œê³ ë¦¬ ì†Œì†
  | 'shares_frame'            // í”„ë ˆì„ ê³µìœ 
  | 'shares_metaphor';        // ì€ìœ  ê³µìœ 
```

### ì—£ì§€ ìë™ ìƒì„± ì•Œê³ ë¦¬ì¦˜

```python
def create_edge_automatically(node1: IdeaNode, node2: IdeaNode) -> IdeaEdge | None:
    """
    ë‘ ë…¸ë“œ ê°„ ì—£ì§€ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±
    """

    # 1. ì°¨ì›ë³„ ìœ ì‚¬ë„ ê³„ì‚°
    dimensions = calculate_multi_dimensional_similarity(node1, node2)

    # 2. ì¢…í•© ê°•ë„ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    strength = (
        dimensions['semantic_similarity'] * 0.35 +
        dimensions['emotional_resonance'] * 0.25 +
        dimensions['pragmatic_alignment'] * 0.20 +
        dimensions['metaphorical_connection'] * 0.15 +
        dimensions['causal_strength'] * 0.05
    )

    # 3. ì„ê³„ê°’ ì²´í¬ (0.65 ì´ìƒë§Œ ì—£ì§€ ìƒì„±)
    if strength < 0.65:
        return None

    # 4. ê´€ê³„ ìœ í˜• ì¶”ë¡ 
    relation_type = infer_relation_type(node1, node2, dimensions)

    # 5. ì–‘ë°©í–¥ì„± íŒë‹¨
    bidirectional = is_bidirectional(relation_type)

    # 6. ì„¤ëª… ìƒì„±
    reasoning = generate_reasoning(node1, node2, relation_type, dimensions)

    # 7. ì—£ì§€ ê°ì²´ ìƒì„±
    edge = IdeaEdge(
        id=generate_uuid(),
        from=node1.id,
        to=node2.id,
        relation_type=relation_type,
        strength=strength,
        dimensions=dimensions,
        reasoning=reasoning,
        bidirectional=bidirectional,
        confidence=calculate_confidence(dimensions),
        source='algorithm',
        created_at=datetime.now()
    )

    return edge

def infer_relation_type(node1, node2, dimensions) -> RelationType:
    """ê´€ê³„ ìœ í˜• ìë™ ì¶”ë¡ """

    # ì˜ë¯¸ì  ìœ ì‚¬ë„ê°€ ë§¤ìš° ë†’ìœ¼ë©´
    if dimensions['semantic_similarity'] > 0.85:
        return 'similar_to'

    # ê°ì •ì´ ë¹„ìŠ·í•˜ë©´
    if dimensions['emotional_resonance'] > 0.8:
        return 'evokes_same_emotion'

    # ê°™ì€ ì€ìœ  ì‹œìŠ¤í…œì„ ê³µìœ í•˜ë©´
    if dimensions['metaphorical_connection'] > 0.8:
        return 'shares_metaphor'

    # ì¸ê³¼ ê´€ê³„ ë§ˆì»¤ê°€ ìˆìœ¼ë©´
    if has_causal_markers(node1, node2):
        return 'causes' if dimensions['causal_strength'] > 0.7 else 'contributes_to'

    # í”„ë ˆì„ì´ ê°™ìœ¼ë©´
    if shares_frame(node1, node2):
        return 'shares_frame'

    # ê¸°ë³¸ê°’
    return 'similar_to'
```

---

## 2.3 ì„ë² ë”© ì „ëµ

### ë‹¤ì¤‘ ì„ë² ë”© ì‹œìŠ¤í…œ

**ëª©ì **: ì„œë¡œ ë‹¤ë¥¸ ì°¨ì›ì˜ ìœ ì‚¬ë„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°

```python
# scripts/embeddings/multi_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List
import pickle

class MultiEmbeddingSystem:
    """ë‹¤ì¤‘ ì„ë² ë”© ìƒì„± ë° ê´€ë¦¬"""

    def __init__(self):
        print("ğŸ”§ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")

        # 1. ì˜ë¯¸ì  ì„ë² ë”©
        self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… Semantic ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        # 2. ê°ì •ì  ì„ë² ë”©
        self.emotion_model = SentenceTransformer('j-hartmann/emotion-english-distilroberta-base')
        print("âœ… Emotion ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        # 3. ë‹¤êµ­ì–´ ì„ë² ë”© (í•œêµ­ì–´ ì§€ì›)
        self.multilingual_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        print("âœ… Multilingual ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        # ìºì‹œ
        self.cache = {}

    def encode_node(self, node: IdeaNode) -> Dict[str, np.ndarray]:
        """ë…¸ë“œë¥¼ ë‹¤ì¤‘ ì„ë² ë”©ìœ¼ë¡œ ì¸ì½”ë”©"""

        # ìºì‹œ ì²´í¬
        if node.id in self.cache:
            return self.cache[node.id]

        content = node.content
        content_ko = node.content_ko or content

        # ì„ë² ë”© ìƒì„±
        embeddings = {
            'semantic': self.semantic_model.encode(content),
            'emotional': self.emotion_model.encode(content),
            'multilingual': self.multilingual_model.encode(content_ko)
        }

        # ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìµœì í™”)
        for key in embeddings:
            embeddings[key] = embeddings[key] / np.linalg.norm(embeddings[key])

        # ìºì‹œ ì €ì¥
        self.cache[node.id] = embeddings

        return embeddings

    def batch_encode(self, nodes: List[IdeaNode]) -> Dict[str, List[np.ndarray]]:
        """ë°°ì¹˜ ì¸ì½”ë”© (íš¨ìœ¨ì )"""

        contents = [node.content for node in nodes]
        contents_ko = [node.content_ko or node.content for node in nodes]

        # ë°°ì¹˜ ì²˜ë¦¬
        semantic_batch = self.semantic_model.encode(contents, show_progress_bar=True)
        emotional_batch = self.emotion_model.encode(contents, show_progress_bar=True)
        multilingual_batch = self.multilingual_model.encode(contents_ko, show_progress_bar=True)

        # ì •ê·œí™”
        semantic_batch = semantic_batch / np.linalg.norm(semantic_batch, axis=1, keepdims=True)
        emotional_batch = emotional_batch / np.linalg.norm(emotional_batch, axis=1, keepdims=True)
        multilingual_batch = multilingual_batch / np.linalg.norm(multilingual_batch, axis=1, keepdims=True)

        return {
            'semantic': semantic_batch,
            'emotional': emotional_batch,
            'multilingual': multilingual_batch
        }

    def save_cache(self, filepath: str):
        """ìºì‹œ ì €ì¥"""
        with open(filepath, 'wb') as f:
            pickle.dump(self.cache, f)
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {filepath}")

    def load_cache(self, filepath: str):
        """ìºì‹œ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            self.cache = pickle.load(f)
        print(f"ğŸ“‚ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(self.cache)}ê°œ í•­ëª©")
```

### ë²¡í„° ì¸ë±ì‹± (FAISS)

**ëª©ì **: 50,000ê°œ ë…¸ë“œì—ì„œ ë¹ ë¥¸ ìœ ì‚¬ë„ ê²€ìƒ‰

```python
# scripts/embeddings/vector_index.py

import faiss
import numpy as np
from typing import List, Tuple

class VectorIndex:
    """FAISS ê¸°ë°˜ ë²¡í„° ì¸ë±ìŠ¤"""

    def __init__(self, dimension: int = 768):
        self.dimension = dimension

        # FAISS ì¸ë±ìŠ¤ ìƒì„± (Inner Product = ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        self.index = faiss.IndexFlatIP(dimension)

        # ID ë§¤í•‘
        self.id_to_idx = {}  # node_id -> index
        self.idx_to_id = {}  # index -> node_id

        self.next_idx = 0

    def add_vector(self, node_id: str, vector: np.ndarray):
        """ë²¡í„° ì¶”ê°€"""

        # ì •ê·œí™” í™•ì¸
        if np.linalg.norm(vector) - 1.0 > 1e-6:
            vector = vector / np.linalg.norm(vector)

        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(vector.reshape(1, -1))

        # ë§¤í•‘ ì €ì¥
        self.id_to_idx[node_id] = self.next_idx
        self.idx_to_id[self.next_idx] = node_id

        self.next_idx += 1

    def batch_add(self, node_ids: List[str], vectors: np.ndarray):
        """ë°°ì¹˜ ì¶”ê°€"""

        # ì •ê·œí™”
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        vectors = vectors / norms

        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(vectors)

        # ë§¤í•‘ ì €ì¥
        for node_id in node_ids:
            self.id_to_idx[node_id] = self.next_idx
            self.idx_to_id[self.next_idx] = node_id
            self.next_idx += 1

    def search(self, query_vector: np.ndarray, k: int = 10) -> List[Tuple[str, float]]:
        """ê°€ì¥ ìœ ì‚¬í•œ kê°œ ë…¸ë“œ ê²€ìƒ‰"""

        # ì •ê·œí™”
        query_vector = query_vector / np.linalg.norm(query_vector)

        # ê²€ìƒ‰
        distances, indices = self.index.search(query_vector.reshape(1, -1), k)

        # ê²°ê³¼ ë³€í™˜
        results = []
        for idx, distance in zip(indices[0], distances[0]):
            if idx in self.idx_to_id:
                node_id = self.idx_to_id[idx]
                similarity = float(distance)  # Inner Product = ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                results.append((node_id, similarity))

        return results

    def save(self, filepath: str):
        """ì¸ë±ìŠ¤ ì €ì¥"""
        faiss.write_index(self.index, filepath)

        # ë§¤í•‘ ì €ì¥
        import pickle
        with open(filepath + '.mapping', 'wb') as f:
            pickle.dump((self.id_to_idx, self.idx_to_id, self.next_idx), f)

        print(f"ğŸ’¾ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {filepath}")

    def load(self, filepath: str):
        """ì¸ë±ìŠ¤ ë¡œë“œ"""
        self.index = faiss.read_index(filepath)

        # ë§¤í•‘ ë¡œë“œ
        import pickle
        with open(filepath + '.mapping', 'rb') as f:
            self.id_to_idx, self.idx_to_id, self.next_idx = pickle.load(f)

        print(f"ğŸ“‚ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {self.next_idx}ê°œ ë²¡í„°")
```

---

## 2.4 NAS ì €ì¥ì†Œ ì„¤ê³„

### í´ë” êµ¬ì¡°

```
/Volumes/work-sync/project/ideamemo/
â”œâ”€â”€ nodes/                          # ë…¸ë“œ ë°ì´í„°
â”‚   â”œâ”€â”€ famous-quote/
â”‚   â”‚   â”œâ”€â”€ en/
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_0001.json     # 1,000ê°œì”©
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_0002.json
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ko/
â”‚   â”‚       â”œâ”€â”€ batch_0001.json
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ book/
â”‚   â”‚   â”œâ”€â”€ classic/
â”‚   â”‚   â”œâ”€â”€ self-help/
â”‚   â”‚   â””â”€â”€ philosophy/
â”‚   â”œâ”€â”€ movie/
â”‚   â”œâ”€â”€ proverb/
â”‚   â”œâ”€â”€ academic/
â”‚   â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ essay/
â”‚   â”œâ”€â”€ poem/
â”‚   â”œâ”€â”€ drama/
â”‚   â””â”€â”€ animation/
â”‚
â”œâ”€â”€ edges/                          # ì—£ì§€ ë°ì´í„°
â”‚   â”œâ”€â”€ semantic/                   # ì˜ë¯¸ì  ê´€ê³„
â”‚   â”œâ”€â”€ emotional/                  # ê°ì •ì  ê´€ê³„
â”‚   â”œâ”€â”€ causal/                     # ì¸ê³¼ ê´€ê³„
â”‚   â””â”€â”€ metaphorical/               # ì€ìœ ì  ê´€ê³„
â”‚
â”œâ”€â”€ embeddings/                     # ì„ë² ë”© ë²¡í„°
â”‚   â”œâ”€â”€ semantic/
â”‚   â”‚   â”œâ”€â”€ vectors.faiss           # FAISS ì¸ë±ìŠ¤
â”‚   â”‚   â””â”€â”€ vectors.faiss.mapping   # ID ë§¤í•‘
â”‚   â”œâ”€â”€ emotional/
â”‚   â””â”€â”€ multilingual/
â”‚
â”œâ”€â”€ indexes/                        # ë©”íƒ€ ì¸ë±ìŠ¤
â”‚   â”œâ”€â”€ master_index.json           # ì „ì²´ ë…¸ë“œ ëª©ë¡
â”‚   â”œâ”€â”€ category_index.json         # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
â”‚   â”œâ”€â”€ keyword_index.json          # í‚¤ì›Œë“œ ì—­ìƒ‰ì¸
â”‚   â”œâ”€â”€ frame_index.json            # í”„ë ˆì„ë³„ ë…¸ë“œ
â”‚   â””â”€â”€ metaphor_index.json         # ì€ìœ ë³„ ë…¸ë“œ
â”‚
â”œâ”€â”€ quality/                        # í’ˆì§ˆ ê´€ë¦¬
â”‚   â”œâ”€â”€ validation_reports/
â”‚   â”œâ”€â”€ curated_nodes.json          # ì „ë¬¸ê°€ ê²€ì¦ ì™„ë£Œ
â”‚   â””â”€â”€ flagged_nodes.json          # ë¬¸ì œ ìˆëŠ” ë…¸ë“œ
â”‚
â””â”€â”€ versions/                       # ë²„ì „ ê´€ë¦¬
    â”œâ”€â”€ v1.0/
    â”œâ”€â”€ v1.1/
    â””â”€â”€ v2.0/
```

### ë°ì´í„° íŒŒì¼ í¬ë§·

#### nodes/famous-quote/en/batch_0001.json
```json
{
  "batch_info": {
    "version": "2.0",
    "created_at": "2025-11-10T12:00:00Z",
    "node_count": 1000,
    "category": "famous-quote",
    "language": "en"
  },
  "nodes": [
    {
      "id": "fq_en_001",
      "content": "We are what we repeatedly do. Excellence, then, is not an act, but a habit.",
      "source": {
        "author": "Aristotle",
        "year": -350,
        "verified": true
      },
      "linguistic": {
        "primary_frame": "identity_formation",
        "metaphors": [
          {
            "system": "identity_is_construction",
            "strength": 0.85
          }
        ]
      },
      "embeddings": {
        "semantic": [...],
        "emotional": [...],
        "pragmatic": [...]
      }
    },
    ...
  ]
}
```

#### edges/semantic/batch_0001.json
```json
{
  "batch_info": {
    "version": "2.0",
    "created_at": "2025-11-10T14:00:00Z",
    "edge_count": 5000,
    "relation_type": "semantic"
  },
  "edges": [
    {
      "id": "edge_001",
      "from": "fq_en_001",
      "to": "fq_en_042",
      "relation_type": "similar_to",
      "strength": 0.87,
      "dimensions": {
        "semantic_similarity": 0.92,
        "emotional_resonance": 0.75
      },
      "reasoning": {
        "automatic": "Both quotes discuss habit formation and identity",
        "evidence": ["shared frame: habit_formation", "similar keywords"]
      }
    },
    ...
  ]
}
```

#### indexes/master_index.json
```json
{
  "version": "2.0",
  "updated_at": "2025-11-10T20:00:00Z",
  "stats": {
    "total_nodes": 52000,
    "total_edges": 548000,
    "categories": {
      "famous-quote": 10000,
      "book": 8000,
      "movie": 7000,
      "academic": 6000,
      "proverb": 5000,
      "web": 5000,
      "essay": 4000,
      "poem": 3000,
      "drama": 2000,
      "animation": 2000
    }
  },
  "files": [
    {
      "path": "nodes/famous-quote/en/batch_0001.json",
      "node_count": 1000,
      "size_mb": 15.3,
      "checksum": "sha256:abc123..."
    },
    ...
  ]
}
```

---

**Part 2 ì™„ë£Œ! ì´ì œ Part 3 ì‘ì„± ì¤‘...**

